{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Auto-Keras is an open source software library for automated machine learning (AutoML). It is developed by DATA Lab at Texas A&M University and community contributors. The ultimate goal of AutoML is to provide easily accessible deep learning tools to domain experts with limited data science or machine learning background. Auto-Keras provides functions to automatically search for architecture and hyperparameters of deep learning models. Installation To install the package, please use the pip installation as follows: pip install autokeras Note: currently, Auto-Keras is only compatible with: Python 3.6 . Example Here is a short example of using the package. import autokeras as ak clf = ak.ImageClassifier() clf.fit(x_train, y_train) results = clf.predict(x_test) Community You can use Gitter to communicate with people who are also interested in Auto-Keras. You can follow us on Twitter. Follow @autokeras Cite this work Auto-Keras: Efficient Neural Architecture Search with Network Morphism. Haifeng Jin, Qingquan Song, and Xia Hu. arXiv:1806.10282 . Biblatex entry: @online{jin2018efficient, author = {Haifeng Jin and Qingquan Song and Xia Hu}, title = {Auto-Keras: Efficient Neural Architecture Search with Network Morphism}, date = {2018-06-27}, year = {2018}, eprintclass = {cs.LG}, eprinttype = {arXiv}, eprint = {cs.LG/1806.10282}, } Support Auto-Keras We accept donations on Open Collective . Thank every backer for supporting us! DISCLAIMER Please note that this is a pre-release version of the Auto-Keras which is still undergoing final testing before its official release. The website, its software and all content found on it are provided on an \u201cas is\u201d and \u201cas available\u201d basis. Auto-Keras does not give any warranties, whether express or implied, as to the suitability or usability of the website, its software or any of its content. Auto-Keras will not be liable for any loss, whether such loss is direct, indirect, special or consequential, suffered by any party as a result of their use of the libraries or content. Any usage of the libraries is done at the user\u2019s own risk and the user will be solely responsible for any damage to any computer system or loss of data that results from such activities. Should you encounter any bugs, glitches, lack of functionality or other problems on the website, please let us know immediately so we can rectify these accordingly. Your help in this regard is greatly appreciated. Acknowledgements The authors gratefully acknowledge the D3M program of the Defense Advanced Research Projects Agency (DARPA) administered through AFRL contract FA8750-17-2-0116; the Texas A&M College of Engineering, and Texas A&M.","title":"Home"},{"location":"#installation","text":"To install the package, please use the pip installation as follows: pip install autokeras Note: currently, Auto-Keras is only compatible with: Python 3.6 .","title":"Installation"},{"location":"#example","text":"Here is a short example of using the package. import autokeras as ak clf = ak.ImageClassifier() clf.fit(x_train, y_train) results = clf.predict(x_test)","title":"Example"},{"location":"#community","text":"You can use Gitter to communicate with people who are also interested in Auto-Keras. You can follow us on Twitter. Follow @autokeras","title":"Community"},{"location":"#cite-this-work","text":"Auto-Keras: Efficient Neural Architecture Search with Network Morphism. Haifeng Jin, Qingquan Song, and Xia Hu. arXiv:1806.10282 . Biblatex entry: @online{jin2018efficient, author = {Haifeng Jin and Qingquan Song and Xia Hu}, title = {Auto-Keras: Efficient Neural Architecture Search with Network Morphism}, date = {2018-06-27}, year = {2018}, eprintclass = {cs.LG}, eprinttype = {arXiv}, eprint = {cs.LG/1806.10282}, }","title":"Cite this work"},{"location":"#support-auto-keras","text":"We accept donations on Open Collective . Thank every backer for supporting us!","title":"Support Auto-Keras"},{"location":"#disclaimer","text":"Please note that this is a pre-release version of the Auto-Keras which is still undergoing final testing before its official release. The website, its software and all content found on it are provided on an \u201cas is\u201d and \u201cas available\u201d basis. Auto-Keras does not give any warranties, whether express or implied, as to the suitability or usability of the website, its software or any of its content. Auto-Keras will not be liable for any loss, whether such loss is direct, indirect, special or consequential, suffered by any party as a result of their use of the libraries or content. Any usage of the libraries is done at the user\u2019s own risk and the user will be solely responsible for any damage to any computer system or loss of data that results from such activities. Should you encounter any bugs, glitches, lack of functionality or other problems on the website, please let us know immediately so we can rectify these accordingly. Your help in this regard is greatly appreciated.","title":"DISCLAIMER"},{"location":"#acknowledgements","text":"The authors gratefully acknowledge the D3M program of the Defense Advanced Research Projects Agency (DARPA) administered through AFRL contract FA8750-17-2-0116; the Texas A&M College of Engineering, and Texas A&M.","title":"Acknowledgements"},{"location":"about/","text":"About This package is developed by DATA LAB at Texas A&M University and community contributors. Main Contributors Haifeng Jin : Designed and developed the overall framework. Implemented Bayesian optimization and network morphism. Develop the pytorch backend. Qingquan Song : Developed the keras backend. Implemented the tabular data classification and regression module. Wrote the getting started tutorial. Tsung-Lin Yang : Implemented ResNet and DenseNet Generator. Support Google Colab, and Multi-GPU training. Refactored CnnModule interface. Added accurate Timeout control support. Yashwanth Reddy : Created MLP and CNN module. Created pretrained model for face detection. Satya Kesav : Supported multiple dimensions of image (e.g. 1D, 3D Convolution) and processing datasets having arbitrary image sizes Developed the BERT based Natural Language API for AutoKeras, including two pretrained models of sentiment analysis and topic classifier. and generic modules for text classification and regression. Xia \"Ben\" Hu : Project lead and maintainer.","title":"About"},{"location":"about/#about","text":"This package is developed by DATA LAB at Texas A&M University and community contributors.","title":"About"},{"location":"about/#main-contributors","text":"Haifeng Jin : Designed and developed the overall framework. Implemented Bayesian optimization and network morphism. Develop the pytorch backend. Qingquan Song : Developed the keras backend. Implemented the tabular data classification and regression module. Wrote the getting started tutorial. Tsung-Lin Yang : Implemented ResNet and DenseNet Generator. Support Google Colab, and Multi-GPU training. Refactored CnnModule interface. Added accurate Timeout control support. Yashwanth Reddy : Created MLP and CNN module. Created pretrained model for face detection. Satya Kesav : Supported multiple dimensions of image (e.g. 1D, 3D Convolution) and processing datasets having arbitrary image sizes Developed the BERT based Natural Language API for AutoKeras, including two pretrained models of sentiment analysis and topic classifier. and generic modules for text classification and regression. Xia \"Ben\" Hu : Project lead and maintainer.","title":"Main Contributors"},{"location":"docker/","text":"Auto-Keras Docker Download Auto-Keras Docker image The following command download Auto-Keras docker image to your machine. docker pull garawalid/autokeras:latest Image releases are tagged using the following format: Tag Description latest Auto-Keras image devel Auto-Keras image that tracks Github repository Start Auto-Keras Docker container docker run -it --shm-size 2G garawalid/autokeras /bin/bash In case you need more memory to run the container, change the value of shm-size . ( Docker run reference ) Run application : To run a local script file.py using Auto-Keras within the container, mount the host directory -v hostDir:/app . docker run -it -v hostDir:/app --shm-size 2G garawalid/autokeras python file.py Example : Let's download the mnist example and run it within the container. Download the example : curl https://raw.githubusercontent.com/keras-team/autokeras/master/examples/a_simple_example/mnist.py --output mnist.py Run the mnist example : docker run -it -v \"$(pwd)\":/app --shm-size 2G garawalid/autokeras python mnist.py","title":"Docker"},{"location":"docker/#auto-keras-docker","text":"","title":"Auto-Keras Docker"},{"location":"docker/#download-auto-keras-docker-image","text":"The following command download Auto-Keras docker image to your machine. docker pull garawalid/autokeras:latest Image releases are tagged using the following format: Tag Description latest Auto-Keras image devel Auto-Keras image that tracks Github repository","title":"Download Auto-Keras Docker image"},{"location":"docker/#start-auto-keras-docker-container","text":"docker run -it --shm-size 2G garawalid/autokeras /bin/bash In case you need more memory to run the container, change the value of shm-size . ( Docker run reference )","title":"Start Auto-Keras Docker container"},{"location":"docker/#run-application","text":"To run a local script file.py using Auto-Keras within the container, mount the host directory -v hostDir:/app . docker run -it -v hostDir:/app --shm-size 2G garawalid/autokeras python file.py","title":"Run application :"},{"location":"docker/#example","text":"Let's download the mnist example and run it within the container. Download the example : curl https://raw.githubusercontent.com/keras-team/autokeras/master/examples/a_simple_example/mnist.py --output mnist.py Run the mnist example : docker run -it -v \"$(pwd)\":/app --shm-size 2G garawalid/autokeras python mnist.py","title":"Example :"},{"location":"nas/","text":"Neural Architecture Search To help the researchers to do experiments on neural architecture search (NAS), we have implemented several baseline methods using the Auto-Keras framework. The implementations are easy since only the core part of the search algorithm is needed. All other parts of NAS (e.g. data structures for storing neural architectures, training of the neural networks) are done by the Auto-Keras framework. Why implement NAS papers in Auto-Keras? The NAS papers usually evaluate their work with the same dataset (e.g. CIFAR10), but they are not directly comparable because of the data preparation and training process are different, the influence of which are significant enough to change the rankings of these NAS methods. We have implemented some of the NAS methods in the framework. More state-of-the-art methods are in progress. There are three advantages of implementing the NAS methods in Auto-Keras. First, it fairly compares the NAS methods independent from other factors (e.g. the choice of optimizer, data augmentation). Second, researchers can easily change the experiment datasets used for NAS. Many of the currently available NAS implementations couple too much with the dataset used, which makes it hard to replace the original dataset with a new one. Third, it saves the effort of finding and running code from different sources. Different code may have different requirements of dependencies and environments, which may conflict with each other. Baseline methods implemented We have implemented four NAS baseline methods: random search : we explore the search space via morphing the network architectures randomly, so the actual performance of the generated neural architecture has no effect on later search. grid search : we manually specified subset of the hyperparameter space to search, i.e., the number of layers and the width of the layers are predefined. greed search : we explore the search space in a greedy way. The \"greedy\" here means the base architecture for the next iteration of search is chosen from those generated by current iteration, the one that have best performance on the training/validation set in our implementation. bayesian optimization : it's the default search strategy of Auto-Keras currently. refer arXiv:1806.10282 for more detail. How to run the baseline methods? Refer to examples/nas/cifar10_tutorial.py for more details. How to implement your own search? To implement your own NAS searcher, you need to implement your own searcher class YOUR_SEARCHER, which is derived from base Searcher class. For your YOUR_SEARCHER class, you must provide implementation of the two abstract method: generate(self, multiprocessing_queue) , which is invoked to generate the next neural architecture. The return value of the generate function should be two elements. The first one is the generated graph. The second one is any other information you want to pass to the update function. If you have multiple values to pass, you need to put them into one tuple. If you don't have any value to pass, you can just put None. update(self, other_info, model_id, graph, metric_value) , which is invoked to update the controller with evaluation result of a neural architecture. The graph and other_info in the parameters are the corresponding return value of the generate function. There is no required return value for this function. You can refer to the default BayesianSearcher as an example. The generate function returns the generated graph and the father ID of the graph in the search tree. Then when the generated model finish training, the father ID ( other_info ) and ID ( model_id ) and instance ( graph ) and metric value ( metric_value ) of the model are passed to update function to update the controller BayesianOptimizer . You can find more example here . You are welcome to implement your own method for NAS in our framework. If it works well, we are happy to merge it into our repo.","title":"Neural Architecture Search"},{"location":"nas/#neural-architecture-search","text":"To help the researchers to do experiments on neural architecture search (NAS), we have implemented several baseline methods using the Auto-Keras framework. The implementations are easy since only the core part of the search algorithm is needed. All other parts of NAS (e.g. data structures for storing neural architectures, training of the neural networks) are done by the Auto-Keras framework.","title":"Neural Architecture Search"},{"location":"nas/#why-implement-nas-papers-in-auto-keras","text":"The NAS papers usually evaluate their work with the same dataset (e.g. CIFAR10), but they are not directly comparable because of the data preparation and training process are different, the influence of which are significant enough to change the rankings of these NAS methods. We have implemented some of the NAS methods in the framework. More state-of-the-art methods are in progress. There are three advantages of implementing the NAS methods in Auto-Keras. First, it fairly compares the NAS methods independent from other factors (e.g. the choice of optimizer, data augmentation). Second, researchers can easily change the experiment datasets used for NAS. Many of the currently available NAS implementations couple too much with the dataset used, which makes it hard to replace the original dataset with a new one. Third, it saves the effort of finding and running code from different sources. Different code may have different requirements of dependencies and environments, which may conflict with each other.","title":"Why implement NAS papers in Auto-Keras?"},{"location":"nas/#baseline-methods-implemented","text":"We have implemented four NAS baseline methods: random search : we explore the search space via morphing the network architectures randomly, so the actual performance of the generated neural architecture has no effect on later search. grid search : we manually specified subset of the hyperparameter space to search, i.e., the number of layers and the width of the layers are predefined. greed search : we explore the search space in a greedy way. The \"greedy\" here means the base architecture for the next iteration of search is chosen from those generated by current iteration, the one that have best performance on the training/validation set in our implementation. bayesian optimization : it's the default search strategy of Auto-Keras currently. refer arXiv:1806.10282 for more detail.","title":"Baseline methods implemented"},{"location":"nas/#how-to-run-the-baseline-methods","text":"Refer to examples/nas/cifar10_tutorial.py for more details.","title":"How to run the baseline methods?"},{"location":"nas/#how-to-implement-your-own-search","text":"To implement your own NAS searcher, you need to implement your own searcher class YOUR_SEARCHER, which is derived from base Searcher class. For your YOUR_SEARCHER class, you must provide implementation of the two abstract method: generate(self, multiprocessing_queue) , which is invoked to generate the next neural architecture. The return value of the generate function should be two elements. The first one is the generated graph. The second one is any other information you want to pass to the update function. If you have multiple values to pass, you need to put them into one tuple. If you don't have any value to pass, you can just put None. update(self, other_info, model_id, graph, metric_value) , which is invoked to update the controller with evaluation result of a neural architecture. The graph and other_info in the parameters are the corresponding return value of the generate function. There is no required return value for this function. You can refer to the default BayesianSearcher as an example. The generate function returns the generated graph and the father ID of the graph in the search tree. Then when the generated model finish training, the father ID ( other_info ) and ID ( model_id ) and instance ( graph ) and metric value ( metric_value ) of the model are passed to update function to update the controller BayesianOptimizer . You can find more example here . You are welcome to implement your own method for NAS in our framework. If it works well, we are happy to merge it into our repo.","title":"How to implement your own search?"},{"location":"start/","text":"Getting Started Installation The installation of Auto-Keras is the same as other python packages. Note: currently, Auto-Keras is only compatible with: Python 3.6 . Latest Stable Version ( pip installation): You can run the following pip installation command in your terminal to install the latest stable version. pip install autokeras Bleeding Edge Version (manual installation): If you want to install the latest development version. You need to download the code from the GitHub repo and run the following commands in the project directory. pip install -r requirements.txt python setup.py install A Simple Example We show an example of image classification on the MNIST dataset, which is a famous benchmark image dataset for hand-written digits classification. Auto-Keras supports different types of data inputs. Data with numpy array (.npy) format. [source] If the images and the labels are already formatted into numpy arrays, you can from keras.datasets import mnist from autokeras.image.image_supervised import ImageClassifier if __name__ == '__main__': (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train = x_train.reshape(x_train.shape + (1,)) x_test = x_test.reshape(x_test.shape + (1,)) clf = ImageClassifier(verbose=True) clf.fit(x_train, y_train, time_limit=12 * 60 * 60) clf.final_fit(x_train, y_train, x_test, y_test, retrain=True) y = clf.evaluate(x_test, y_test) print(y) In the example above, the images and the labels are already formatted into numpy arrays. What if your data are raw image files ( e.g. .jpg, .png, .bmp)? [source] You can use our load_image_dataset function to load the images and their labels as follows. from autokeras.image.image_supervised import load_image_dataset x_train, y_train = load_image_dataset(csv_file_path=\"train/label.csv\", images_path=\"train\") print(x_train.shape) print(y_train.shape) x_test, y_test = load_image_dataset(csv_file_path=\"test/label.csv\", images_path=\"test\") print(x_test.shape) print(y_test.shape) The argument csv_file_path is the path to the CSV file containing the image file names and their corresponding labels. Both csv files and the raw image datasets could be downloaded from link . Here is an example of the csv file. File Name,Label 00000.jpg,5 00001.jpg,0 00002.jpg,4 00003.jpg,1 00004.jpg,9 00005.jpg,2 00006.jpg,1 ... The second argument images_path is the path to the directory containing all the images with those file names listed in the CSV file. The returned values x_train and y_train are the numpy arrays, which can be directly feed into the fit function of ImageClassifier . This CSV file for train or test can be created from folders containing images of a specific class (meaning label): train \u2514\u2500\u2500\u2500class_1 \u2502 \u2502 class_1_image_1.png \u2502 \u2502 class_1_image_2.png | | ... \u2514\u2500\u2500\u2500class_2 \u2502 class_2_image_1.png \u2502 class_2_image_2.png | ... The code below shows an example of how to create the CSV: train_dir = 'train' # Path to the train directory class_dirs = [i for i in os.listdir(path=train_dir) if os.path.isdir(os.path.join(train_dir, i))] with open('train/label.csv', 'w') as train_csv: fieldnames = ['File Name', 'Label'] writer = csv.DictWriter(train_csv, fieldnames=fieldnames) writer.writeheader() label = 0 for current_class in class_dirs: for image in os.listdir(os.path.join(train_dir, current_class)): writer.writerow({'File Name': str(image), 'Label':label}) label += 1 train_csv.close() Enable Multi-GPU Training Auto-Keras support multiple GPU training in the default setting. There's no additional step needed to enable multiple GPU training. However, if multiple-GPU training is not a desirable behavior. You can disable it via environmental variable. CUDA_VISIBLE_DEVICES . For example, in your bash: export CUDA_VISIBLE_DEVICES=0 . Keep in mind that when using multiple-GPU, make sure batch size is big enough that multiple-gpu context switch overhead won't effect the performance too much. Otherwise multiple-gpu training may be slower than single-GPU training. Portable Models How to export Portable model? [source] from autokeras import ImageClassifier clf = ImageClassifier(verbose=True, augment=False) clf.export_autokeras_model(model_file_name) The model will be stored into the path model_file_name . How to load exported Portable model? [source] from autokeras.utils import pickle_from_file model = pickle_from_file(model_file_name) results = model.evaluate(x_test, y_test) print(results) The model will be loaded from the path model_file_name and then you can use the functions listed in PortableImageSupervised . Model Visualizations How to visualize the best selected architecture? [source] While trying to create a model, let's say an Image classifier on MNIST, there is a facility for the user to visualize a .PDF depiction of the best architecture that was chosen by autokeras, after model training is complete. Prerequisites : 1) graphviz must be installed in your system. Refer Installation Guide 2) Additionally, also install \"graphviz\" python package using pip / conda pip: pip install graphviz conda : conda install -c conda-forge python-graphviz If the above installations are complete, proceed with the following steps : Step 1 : Specify a path before starting your model training clf = ImageClassifier(path=\"~/automodels/\",verbose=True, augment=False) # Give a custom path of your choice clf.fit(x_train, y_train, time_limit=30 * 60) clf.final_fit(x_train, y_train, x_test, y_test, retrain=True) Step 2 : After the model training is complete, run examples/visualize.py , whilst passing the same path as parameter if __name__ == '__main__': visualize('~/automodels/') Net Modules MlpModule tutorial. [source] MlpGenerator in net_module.py is a child class of Networkmodule . It can generates neural architecture with MLP modules Normally, there's two place to call the MlpGenerator, one is call MlpGenerator.fit while the other is MlpGenerator.final_fit . For example, in a image classification class ImageClassifier , one can initialize the cnn module as: mlpModule = MlpModule(loss, metric, searcher_args, path, verbose) Where: * loss and metric determines by the type of training model(classification or regression or others) * search_args can be referred in search.py * path is the path to store the whole searching process and generated model. * verbose is a boolean. Setting it to true prints to stdout. Then, for the searching part, one can call: mlpModule.fit(n_output_node, input_shape, train_data, test_data, time_limit=24 * 60 * 60) where: * n_output_node: A integer value represent the number of output node in the final layer. * input_shape: A tuple to express the shape of every train entry. For example, MNIST dataset would be (28,28,1). * train_data: A PyTorch DataLoader instance representing the training data. * test_data: A PyTorch DataLoader instance representing the testing data. * time_limit: A integer value represents the time limit on searching for models. And for final testing(testing the best searched model), one can call: mlpModule.final_fit(train_data, test_data, trainer_args=None, retrain=False) where: * train_data: A DataLoader instance representing the training data. * test_data: A DataLoader instance representing the testing data. * trainer_args: A dictionary containing the parameters of the ModelTrainer constructor. * retrain: A boolean of whether reinitialize the weights of the model. CnnModule tutorial. [source] CnnGenerator in net_module.py is a child class of Networkmodule . It can generates neural architecture with basic cnn modules and the ResNet module. Normally, there's two place to call the CnnGenerator, one is call CnnGenerator.fit while the other is CnnGenerator.final_fit . For example, in a image classification class ImageClassifier , one can initialize the cnn module as: from autokeras import CnnModule from autokeras.nn.loss_function import classification_loss from autokeras.nn.metric import Accuracy TEST_FOLDER = \"test\" cnnModule = CnnModule(loss=classification_loss, metric=Accuracy, searcher_args={}, path=TEST_FOLDER, verbose=False) Where: * loss and metric determines by the type of training model(classification or regression or others) * search_args can be referred in search.py * path is the path to store the whole searching process and generated model. * verbose is a boolean. Setting it to true prints to stdout. Then, for the searching part, one can call: cnnModule.fit(n_output_node, input_shape, train_data, test_data, time_limit=24 * 60 * 60) where: * n_output_node: A integer value represent the number of output node in the final layer. * input_shape: A tuple to express the shape of every train entry. For example, MNIST dataset would be (28,28,1). * train_data: A PyTorch DataLoader instance representing the training data. * test_data: A PyTorch DataLoader instance representing the testing data. * time_limit: A integer value represents the time limit on searching for models. And for final testing(testing the best searched model), one can call: cnnModule.final_fit(train_data, test_data, trainer_args=None, retrain=False) where: * train_data: A DataLoader instance representing the training data. * test_data: A DataLoader instance representing the testing data. * trainer_args: A dictionary containing the parameters of the ModelTrainer constructor. * retrain: A boolean of whether reinitialize the weights of the model. Task Modules Automated text classifier tutorial. [source] Class TextClassifier and TextRegressor are designed for automated generate best performance cnn neural architecture for a given text dataset. clf = TextClassifier(verbose=True) clf.fit(x=x_train, y=y_train, time_limit=12 * 60 * 60) x_train: string format text data y_train: int format text label After searching the best model, one can call clf.final_fit to test the best model found in searching. Notes: Preprocessing of the text data: * Class TextClassifier and TextRegressor contains a pre-process of the text data. Which means the input data should be in string format. * The default pre-process model uses the glove6B model from Stanford NLP. * To change the default setting of the pre-process model, one need to change the corresponding variable: EMBEDDING_DIM , PRE_TRAIN_FILE_LINK , PRE_TRAIN_FILE_LINK , PRE_TRAIN_FILE_NAME in constant.py . Pretrained Models Object detection tutorial. [source] by Wuyang Chen from Dr. Atlas Wang's group at CSE Department, Texas A&M. class_id_mapping = {0 : \"Business\", 1 : \"Sci/Tech\", 2 : \"Sports\", 3 : \"World\"} ObjectDetector in object_detector.py is a child class of Pretrained . Currently it can load a pretrained SSD model ( Liu, Wei, et al. \"Ssd: Single shot multibox detector.\" European conference on computer vision. Springer, Cham, 2016. ) and find object(s) in a given image. Let's first import the ObjectDetector and create a detection model ( detector ) with from autokeras.pretrained.object_detector import ObjectDetector detector = ObjectDetector() It will automatically download and load the weights into detector . Note: the ObjectDetector class can automatically detect the existance of available cuda device(s), and use the device if exists. Finally you can make predictions against an image: results = detector.predict(\"/path/to/images/000001.jpg\", output_file_path=\"/path/to/images/\") Function detector.predict() requires the path to the image. If the output_file_path is not given, the detector will just return the numerical results as a list of dictionaries. Each dictionary is like {\"left\": int, \"top\": int, \"width\": int, \"height\": int: \"category\": str, \"confidence\": float}, where left and top is the (left, top) coordinates of the bounding box of the object and width and height are width and height of the box. category is a string representing the class the object belongs to, and the confidence can be regarded as the probability that the model believes its prediction is correct. If the output_file_path is given, then the results mentioned above will be plotted and saved in a new image file with suffix \"_prediction\" into the given output_file_path . If you run the example/object_detection/object_detection_example.py, you will get result [{'category': 'person', 'width': 331, 'height': 500, 'left': 17, 'confidence': 0.9741123914718628, 'top': 0}] Sentiment Analysis tutorial. [source] The sentiment analysis module provides an interface to find the sentiment of any text. The pretrained model is obtained by training Google AI\u2019s BERT model on IMDb dataset . Let\u2019s import the SentimentAnalysis module from text_classifier.py . It is derived from the super class TextClassifier which is the child class of Pretrained class. from autokeras.pretrained.text_classifier import SentimentAnalysis sentiment_analysis = SentimentAnalysis() During initialization of SentimentAnalysis , the pretrained model is loaded into memory i.e. CPU\u2019s or GPU\u2019s, if available. Now, you may directly call the predict function in SentimentAnalysis class on any input sentence provided as a string as shown below. The function returns a value between 0 and 1. polarity = sentiment_cls.predict(\"The model is working well..\") Note: If the output value of the predict function is close to 0, it implies the statement has negative sentiment, whereas value close to 1 implies positive sentiment. If you run sentiment_analysis_example.py , you should get an output value of 0.9 which implies that the input statement The model is working well.. has strong positive sentiment. Topic Classification tutorial. [source] The topic classifier module provides an interface to find the topic of any text. The pretrained model is obtained by training Google AI\u2019s BERT model on AGNews dataset . Let\u2019s import the TopicClassifier module from text_classifier.py . It is derived from the super class TextClassifier which is the child class of Pretrained class. from autokeras.pretrained.text_classifier import TopicClassifier topic_classifier = TopicClassifier() During initialization of TopicClassifier , the pretrained model is loaded into memory i.e. CPU\u2019s or GPU\u2019s, if available. Now, you may directly call the predict function in TopicClassifier class on any input sentence provided as a string as shown below. The function returns one of the fours topics Business , Sci/Tech , World and Sports . class_name = topic_classifier.predict(\"With some more practice, they will definitely make it to finals..\") If you run topic_classifier_example.py , you should see the predict function returns the label Sports , which is the predicted label for the input statement. Voice generator tutorial. [source] The voice generator is a refactor of deepvoice3 . The structure contains three main parts: Encoder : A fully-convolutional encoder, which converts textual features to an internallearned representation. Decoder : A fully-convolutional causal decoder, which decodes the learned representationwith a multi-hop convolutional attention mechanism into a low-dimensional audio repre-sentation (mel-scale spectrograms) in an autoregressive manner. Converter : A fully-convolutional post-processing network, which predicts final vocoderparameters (depending on the vocoder choice) from the decoder hidden states. Unlike thedecoder, the converter is non-causal and can thus depend on future context information For more details, please refer the original paper: Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning Example: from autokeras.pretrained import VoiceGenerator voice_generator = VoiceGenerator() text = \"The approximation of pi is 3.14\" voice_generator.predict(text, \"test.wav\") Voice recognizer tutorial. [source] The voice recognizer is a refactor of deepspeech . The model structure contains two parts: * Encoder: Convolutional layer followed by recurrent neural network and then fully convert network. Output is the hidden voice information. * Decoder: Decode the hidden voice information to the voice wave. For more details, please refer the original paper: Deep Speech 2: End-to-End Speech Recognition in English and Mandarin Because currently torchaudio does not support pip install. So the current package doesn't support audio parsing part. To use the voice recognizer, one should first parse the audio following the standard below: First, install the torchaudio , the install process can refer the repo. Seconder use the following audio parser from autokeras.constant import Constant import torchaudio import scipy.signal import librosa import torch import numpy as np def load_audio(path): sound, _ = torchaudio.load(path) sound = sound.numpy() if len(sound.shape) > 1: if sound.shape[0] == 1: sound = sound.squeeze() else: sound = sound.mean(axis=0) # multiple channels, average return sound class SpectrogramParser: def __init__(self, audio_conf, normalize=False, augment=False): \"\"\" Parses audio file into spectrogram with optional normalization and various augmentations :param audio_conf: Dictionary containing the sample rate, window and the window length/stride in seconds :param normalize(default False): Apply standard mean and deviation normalization to audio tensor :param augment(default False): Apply random tempo and gain perturbations \"\"\" super(SpectrogramParser, self).__init__() self.window_stride = audio_conf['window_stride'] self.window_size = audio_conf['window_size'] self.sample_rate = audio_conf['sample_rate'] self.window = scipy.signal.hamming self.normalize = normalize self.augment = augment self.noise_prob = audio_conf.get('noise_prob') def parse_audio(self, audio_path): y = load_audio(audio_path) n_fft = int(self.sample_rate * self.window_size) win_length = n_fft hop_length = int(self.sample_rate * self.window_stride) # STFT D = librosa.stft(y, n_fft=n_fft, hop_length=hop_length, win_length=win_length, window=self.window) spect, _ = librosa.magphase(D) # S = log(S+1) spect = np.log1p(spect) spect = torch.FloatTensor(spect) if self.normalize: mean = spect.mean() std = spect.std() spect.add_(-mean) spect.div_(std) return spect parser = SpectrogramParser(Constant.VOICE_RECONGINIZER_AUDIO_CONF, normalize=True) spect = parser.parse_audio(\"test.wav\").contiguous() After this we will have the audio parsed as torch tensor in variable spect . Then we can use the following to recognize the voice: from autokeras.pretrained import VoiceRecognizer voice_recognizer = VoiceRecognizer() print(voice_recognizer.predict(audio_data=spect)) This voice recognizer pretrained model is well tuned based on the AN4 dataset. It has a large probability cannot perform well on other dataset.","title":"Getting Started"},{"location":"start/#getting-started","text":"","title":"Getting Started"},{"location":"start/#installation","text":"The installation of Auto-Keras is the same as other python packages. Note: currently, Auto-Keras is only compatible with: Python 3.6 .","title":"Installation"},{"location":"start/#latest-stable-version-pip-installation","text":"You can run the following pip installation command in your terminal to install the latest stable version. pip install autokeras","title":"Latest Stable Version (pip installation):"},{"location":"start/#bleeding-edge-version-manual-installation","text":"If you want to install the latest development version. You need to download the code from the GitHub repo and run the following commands in the project directory. pip install -r requirements.txt python setup.py install","title":"Bleeding Edge Version (manual installation):"},{"location":"start/#a-simple-example","text":"We show an example of image classification on the MNIST dataset, which is a famous benchmark image dataset for hand-written digits classification. Auto-Keras supports different types of data inputs.","title":"A Simple Example"},{"location":"start/#data-with-numpy-array-npy-format","text":"[source] If the images and the labels are already formatted into numpy arrays, you can from keras.datasets import mnist from autokeras.image.image_supervised import ImageClassifier if __name__ == '__main__': (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train = x_train.reshape(x_train.shape + (1,)) x_test = x_test.reshape(x_test.shape + (1,)) clf = ImageClassifier(verbose=True) clf.fit(x_train, y_train, time_limit=12 * 60 * 60) clf.final_fit(x_train, y_train, x_test, y_test, retrain=True) y = clf.evaluate(x_test, y_test) print(y) In the example above, the images and the labels are already formatted into numpy arrays.","title":"Data with numpy array (.npy) format."},{"location":"start/#what-if-your-data-are-raw-image-files-eg-jpg-png-bmp","text":"[source] You can use our load_image_dataset function to load the images and their labels as follows. from autokeras.image.image_supervised import load_image_dataset x_train, y_train = load_image_dataset(csv_file_path=\"train/label.csv\", images_path=\"train\") print(x_train.shape) print(y_train.shape) x_test, y_test = load_image_dataset(csv_file_path=\"test/label.csv\", images_path=\"test\") print(x_test.shape) print(y_test.shape) The argument csv_file_path is the path to the CSV file containing the image file names and their corresponding labels. Both csv files and the raw image datasets could be downloaded from link . Here is an example of the csv file. File Name,Label 00000.jpg,5 00001.jpg,0 00002.jpg,4 00003.jpg,1 00004.jpg,9 00005.jpg,2 00006.jpg,1 ... The second argument images_path is the path to the directory containing all the images with those file names listed in the CSV file. The returned values x_train and y_train are the numpy arrays, which can be directly feed into the fit function of ImageClassifier . This CSV file for train or test can be created from folders containing images of a specific class (meaning label): train \u2514\u2500\u2500\u2500class_1 \u2502 \u2502 class_1_image_1.png \u2502 \u2502 class_1_image_2.png | | ... \u2514\u2500\u2500\u2500class_2 \u2502 class_2_image_1.png \u2502 class_2_image_2.png | ... The code below shows an example of how to create the CSV: train_dir = 'train' # Path to the train directory class_dirs = [i for i in os.listdir(path=train_dir) if os.path.isdir(os.path.join(train_dir, i))] with open('train/label.csv', 'w') as train_csv: fieldnames = ['File Name', 'Label'] writer = csv.DictWriter(train_csv, fieldnames=fieldnames) writer.writeheader() label = 0 for current_class in class_dirs: for image in os.listdir(os.path.join(train_dir, current_class)): writer.writerow({'File Name': str(image), 'Label':label}) label += 1 train_csv.close()","title":"What if your data are raw image files (e.g. .jpg, .png, .bmp)?"},{"location":"start/#enable-multi-gpu-training","text":"Auto-Keras support multiple GPU training in the default setting. There's no additional step needed to enable multiple GPU training. However, if multiple-GPU training is not a desirable behavior. You can disable it via environmental variable. CUDA_VISIBLE_DEVICES . For example, in your bash: export CUDA_VISIBLE_DEVICES=0 . Keep in mind that when using multiple-GPU, make sure batch size is big enough that multiple-gpu context switch overhead won't effect the performance too much. Otherwise multiple-gpu training may be slower than single-GPU training.","title":"Enable Multi-GPU Training"},{"location":"start/#portable-models","text":"","title":"Portable Models"},{"location":"start/#how-to-export-portable-model","text":"[source] from autokeras import ImageClassifier clf = ImageClassifier(verbose=True, augment=False) clf.export_autokeras_model(model_file_name) The model will be stored into the path model_file_name .","title":"How to export Portable model?"},{"location":"start/#how-to-load-exported-portable-model","text":"[source] from autokeras.utils import pickle_from_file model = pickle_from_file(model_file_name) results = model.evaluate(x_test, y_test) print(results) The model will be loaded from the path model_file_name and then you can use the functions listed in PortableImageSupervised .","title":"How to load exported Portable model?"},{"location":"start/#model-visualizations","text":"","title":"Model Visualizations"},{"location":"start/#how-to-visualize-the-best-selected-architecture","text":"[source] While trying to create a model, let's say an Image classifier on MNIST, there is a facility for the user to visualize a .PDF depiction of the best architecture that was chosen by autokeras, after model training is complete. Prerequisites : 1) graphviz must be installed in your system. Refer Installation Guide 2) Additionally, also install \"graphviz\" python package using pip / conda pip: pip install graphviz conda : conda install -c conda-forge python-graphviz If the above installations are complete, proceed with the following steps : Step 1 : Specify a path before starting your model training clf = ImageClassifier(path=\"~/automodels/\",verbose=True, augment=False) # Give a custom path of your choice clf.fit(x_train, y_train, time_limit=30 * 60) clf.final_fit(x_train, y_train, x_test, y_test, retrain=True) Step 2 : After the model training is complete, run examples/visualize.py , whilst passing the same path as parameter if __name__ == '__main__': visualize('~/automodels/')","title":"How to visualize the best selected architecture?"},{"location":"start/#net-modules","text":"","title":"Net Modules"},{"location":"start/#mlpmodule-tutorial","text":"[source] MlpGenerator in net_module.py is a child class of Networkmodule . It can generates neural architecture with MLP modules Normally, there's two place to call the MlpGenerator, one is call MlpGenerator.fit while the other is MlpGenerator.final_fit . For example, in a image classification class ImageClassifier , one can initialize the cnn module as: mlpModule = MlpModule(loss, metric, searcher_args, path, verbose) Where: * loss and metric determines by the type of training model(classification or regression or others) * search_args can be referred in search.py * path is the path to store the whole searching process and generated model. * verbose is a boolean. Setting it to true prints to stdout. Then, for the searching part, one can call: mlpModule.fit(n_output_node, input_shape, train_data, test_data, time_limit=24 * 60 * 60) where: * n_output_node: A integer value represent the number of output node in the final layer. * input_shape: A tuple to express the shape of every train entry. For example, MNIST dataset would be (28,28,1). * train_data: A PyTorch DataLoader instance representing the training data. * test_data: A PyTorch DataLoader instance representing the testing data. * time_limit: A integer value represents the time limit on searching for models. And for final testing(testing the best searched model), one can call: mlpModule.final_fit(train_data, test_data, trainer_args=None, retrain=False) where: * train_data: A DataLoader instance representing the training data. * test_data: A DataLoader instance representing the testing data. * trainer_args: A dictionary containing the parameters of the ModelTrainer constructor. * retrain: A boolean of whether reinitialize the weights of the model.","title":"MlpModule tutorial."},{"location":"start/#cnnmodule-tutorial","text":"[source] CnnGenerator in net_module.py is a child class of Networkmodule . It can generates neural architecture with basic cnn modules and the ResNet module. Normally, there's two place to call the CnnGenerator, one is call CnnGenerator.fit while the other is CnnGenerator.final_fit . For example, in a image classification class ImageClassifier , one can initialize the cnn module as: from autokeras import CnnModule from autokeras.nn.loss_function import classification_loss from autokeras.nn.metric import Accuracy TEST_FOLDER = \"test\" cnnModule = CnnModule(loss=classification_loss, metric=Accuracy, searcher_args={}, path=TEST_FOLDER, verbose=False) Where: * loss and metric determines by the type of training model(classification or regression or others) * search_args can be referred in search.py * path is the path to store the whole searching process and generated model. * verbose is a boolean. Setting it to true prints to stdout. Then, for the searching part, one can call: cnnModule.fit(n_output_node, input_shape, train_data, test_data, time_limit=24 * 60 * 60) where: * n_output_node: A integer value represent the number of output node in the final layer. * input_shape: A tuple to express the shape of every train entry. For example, MNIST dataset would be (28,28,1). * train_data: A PyTorch DataLoader instance representing the training data. * test_data: A PyTorch DataLoader instance representing the testing data. * time_limit: A integer value represents the time limit on searching for models. And for final testing(testing the best searched model), one can call: cnnModule.final_fit(train_data, test_data, trainer_args=None, retrain=False) where: * train_data: A DataLoader instance representing the training data. * test_data: A DataLoader instance representing the testing data. * trainer_args: A dictionary containing the parameters of the ModelTrainer constructor. * retrain: A boolean of whether reinitialize the weights of the model.","title":"CnnModule tutorial."},{"location":"start/#task-modules","text":"","title":"Task Modules"},{"location":"start/#automated-text-classifier-tutorial","text":"[source] Class TextClassifier and TextRegressor are designed for automated generate best performance cnn neural architecture for a given text dataset. clf = TextClassifier(verbose=True) clf.fit(x=x_train, y=y_train, time_limit=12 * 60 * 60) x_train: string format text data y_train: int format text label After searching the best model, one can call clf.final_fit to test the best model found in searching. Notes: Preprocessing of the text data: * Class TextClassifier and TextRegressor contains a pre-process of the text data. Which means the input data should be in string format. * The default pre-process model uses the glove6B model from Stanford NLP. * To change the default setting of the pre-process model, one need to change the corresponding variable: EMBEDDING_DIM , PRE_TRAIN_FILE_LINK , PRE_TRAIN_FILE_LINK , PRE_TRAIN_FILE_NAME in constant.py .","title":"Automated text classifier tutorial."},{"location":"start/#pretrained-models","text":"","title":"Pretrained Models"},{"location":"start/#object-detection-tutorial","text":"[source]","title":"Object detection tutorial."},{"location":"start/#by-wuyang-chen-from-dr-atlas-wangs-group-at-cse-department-texas-am","text":"class_id_mapping = {0 : \"Business\", 1 : \"Sci/Tech\", 2 : \"Sports\", 3 : \"World\"} ObjectDetector in object_detector.py is a child class of Pretrained . Currently it can load a pretrained SSD model ( Liu, Wei, et al. \"Ssd: Single shot multibox detector.\" European conference on computer vision. Springer, Cham, 2016. ) and find object(s) in a given image. Let's first import the ObjectDetector and create a detection model ( detector ) with from autokeras.pretrained.object_detector import ObjectDetector detector = ObjectDetector() It will automatically download and load the weights into detector . Note: the ObjectDetector class can automatically detect the existance of available cuda device(s), and use the device if exists. Finally you can make predictions against an image: results = detector.predict(\"/path/to/images/000001.jpg\", output_file_path=\"/path/to/images/\") Function detector.predict() requires the path to the image. If the output_file_path is not given, the detector will just return the numerical results as a list of dictionaries. Each dictionary is like {\"left\": int, \"top\": int, \"width\": int, \"height\": int: \"category\": str, \"confidence\": float}, where left and top is the (left, top) coordinates of the bounding box of the object and width and height are width and height of the box. category is a string representing the class the object belongs to, and the confidence can be regarded as the probability that the model believes its prediction is correct. If the output_file_path is given, then the results mentioned above will be plotted and saved in a new image file with suffix \"_prediction\" into the given output_file_path . If you run the example/object_detection/object_detection_example.py, you will get result [{'category': 'person', 'width': 331, 'height': 500, 'left': 17, 'confidence': 0.9741123914718628, 'top': 0}]","title":"by Wuyang Chen from Dr. Atlas Wang's group at CSE Department, Texas A&amp;M."},{"location":"start/#sentiment-analysis-tutorial","text":"[source] The sentiment analysis module provides an interface to find the sentiment of any text. The pretrained model is obtained by training Google AI\u2019s BERT model on IMDb dataset . Let\u2019s import the SentimentAnalysis module from text_classifier.py . It is derived from the super class TextClassifier which is the child class of Pretrained class. from autokeras.pretrained.text_classifier import SentimentAnalysis sentiment_analysis = SentimentAnalysis() During initialization of SentimentAnalysis , the pretrained model is loaded into memory i.e. CPU\u2019s or GPU\u2019s, if available. Now, you may directly call the predict function in SentimentAnalysis class on any input sentence provided as a string as shown below. The function returns a value between 0 and 1. polarity = sentiment_cls.predict(\"The model is working well..\") Note: If the output value of the predict function is close to 0, it implies the statement has negative sentiment, whereas value close to 1 implies positive sentiment. If you run sentiment_analysis_example.py , you should get an output value of 0.9 which implies that the input statement The model is working well.. has strong positive sentiment.","title":"Sentiment Analysis tutorial."},{"location":"start/#topic-classification-tutorial","text":"[source] The topic classifier module provides an interface to find the topic of any text. The pretrained model is obtained by training Google AI\u2019s BERT model on AGNews dataset . Let\u2019s import the TopicClassifier module from text_classifier.py . It is derived from the super class TextClassifier which is the child class of Pretrained class. from autokeras.pretrained.text_classifier import TopicClassifier topic_classifier = TopicClassifier() During initialization of TopicClassifier , the pretrained model is loaded into memory i.e. CPU\u2019s or GPU\u2019s, if available. Now, you may directly call the predict function in TopicClassifier class on any input sentence provided as a string as shown below. The function returns one of the fours topics Business , Sci/Tech , World and Sports . class_name = topic_classifier.predict(\"With some more practice, they will definitely make it to finals..\") If you run topic_classifier_example.py , you should see the predict function returns the label Sports , which is the predicted label for the input statement.","title":"Topic Classification tutorial."},{"location":"start/#voice-generator-tutorial","text":"[source] The voice generator is a refactor of deepvoice3 . The structure contains three main parts: Encoder : A fully-convolutional encoder, which converts textual features to an internallearned representation. Decoder : A fully-convolutional causal decoder, which decodes the learned representationwith a multi-hop convolutional attention mechanism into a low-dimensional audio repre-sentation (mel-scale spectrograms) in an autoregressive manner. Converter : A fully-convolutional post-processing network, which predicts final vocoderparameters (depending on the vocoder choice) from the decoder hidden states. Unlike thedecoder, the converter is non-causal and can thus depend on future context information For more details, please refer the original paper: Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning Example: from autokeras.pretrained import VoiceGenerator voice_generator = VoiceGenerator() text = \"The approximation of pi is 3.14\" voice_generator.predict(text, \"test.wav\")","title":"Voice generator tutorial."},{"location":"start/#voice-recognizer-tutorial","text":"[source] The voice recognizer is a refactor of deepspeech . The model structure contains two parts: * Encoder: Convolutional layer followed by recurrent neural network and then fully convert network. Output is the hidden voice information. * Decoder: Decode the hidden voice information to the voice wave. For more details, please refer the original paper: Deep Speech 2: End-to-End Speech Recognition in English and Mandarin Because currently torchaudio does not support pip install. So the current package doesn't support audio parsing part. To use the voice recognizer, one should first parse the audio following the standard below: First, install the torchaudio , the install process can refer the repo. Seconder use the following audio parser from autokeras.constant import Constant import torchaudio import scipy.signal import librosa import torch import numpy as np def load_audio(path): sound, _ = torchaudio.load(path) sound = sound.numpy() if len(sound.shape) > 1: if sound.shape[0] == 1: sound = sound.squeeze() else: sound = sound.mean(axis=0) # multiple channels, average return sound class SpectrogramParser: def __init__(self, audio_conf, normalize=False, augment=False): \"\"\" Parses audio file into spectrogram with optional normalization and various augmentations :param audio_conf: Dictionary containing the sample rate, window and the window length/stride in seconds :param normalize(default False): Apply standard mean and deviation normalization to audio tensor :param augment(default False): Apply random tempo and gain perturbations \"\"\" super(SpectrogramParser, self).__init__() self.window_stride = audio_conf['window_stride'] self.window_size = audio_conf['window_size'] self.sample_rate = audio_conf['sample_rate'] self.window = scipy.signal.hamming self.normalize = normalize self.augment = augment self.noise_prob = audio_conf.get('noise_prob') def parse_audio(self, audio_path): y = load_audio(audio_path) n_fft = int(self.sample_rate * self.window_size) win_length = n_fft hop_length = int(self.sample_rate * self.window_stride) # STFT D = librosa.stft(y, n_fft=n_fft, hop_length=hop_length, win_length=win_length, window=self.window) spect, _ = librosa.magphase(D) # S = log(S+1) spect = np.log1p(spect) spect = torch.FloatTensor(spect) if self.normalize: mean = spect.mean() std = spect.std() spect.add_(-mean) spect.div_(std) return spect parser = SpectrogramParser(Constant.VOICE_RECONGINIZER_AUDIO_CONF, normalize=True) spect = parser.parse_audio(\"test.wav\").contiguous() After this we will have the audio parsed as torch tensor in variable spect . Then we can use the following to recognize the voice: from autokeras.pretrained import VoiceRecognizer voice_recognizer = VoiceRecognizer() print(voice_recognizer.predict(audio_data=spect)) This voice recognizer pretrained model is well tuned based on the AN4 dataset. It has a large probability cannot perform well on other dataset.","title":"Voice recognizer tutorial."},{"location":"temp/bayesian/","text":"layer_distance The distance between two layers. layers_distance The distance between the layers of two neural networks. skip_connection_distance The distance between two skip-connections. skip_connections_distance The distance between the skip-connections of two neural networks. edit_distance The distance between two neural networks. Args: x: An instance of NetworkDescriptor. y: An instance of NetworkDescriptor Returns edit_distance_matrix Calculate the edit distance. Args train_x : A list of neural architectures. train_y : A list of neural architectures. Returns vector_distance The Euclidean distance between two vectors. bourgain_embedding_matrix Use Bourgain algorithm to embed the neural architectures based on their edit-distance. Args distance_matrix : A matrix of edit-distances. Returns contain Check if the target descriptor is in the descriptors. IncrementalGaussianProcess Gaussian process regressor. Attributes alpha : A hyperparameter. fit Fit the regressor with more data. Args train_x : A list of NetworkDescriptor. train_y : A list of metric values. incremental_fit Incrementally fit the regressor. first_fit Fit the regressor for the first time. predict Predict the result. Args train_x : A list of NetworkDescriptor. Returns y_mean : The predicted mean. y_std : The predicted standard deviation. BayesianOptimizer A Bayesian optimizer for neural architectures. Attributes searcher : The Searcher which is calling the Bayesian optimizer. t_min : The minimum temperature for simulated annealing. metric : An instance of the Metric subclasses. gpr : A GaussianProcessRegressor for bayesian optimization. beta : The beta in acquisition function. (refer to our paper) search_tree : The network morphism search tree. fit Fit the optimizer with new architectures and performances. Args x_queue : A list of NetworkDescriptor. y_queue : A list of metric values. generate Generate new architecture. Args descriptors : All the searched neural architectures. timeout : An integer. The time limit in seconds. sync_message : the Queue for multiprocessing return value. Returns graph : An instance of Graph. A morphed neural network with weights. father_id : The father node ID in the search tree. Elem Elements to be sorted according to metric value. ReverseElem Elements to be reversely sorted according to metric value. SearchTree The network morphism search tree. get_dict A recursive function to return the content of the tree in a dict.","title":"bayesian"},{"location":"temp/bayesian/#layer_distance","text":"The distance between two layers.","title":"layer_distance"},{"location":"temp/bayesian/#layers_distance","text":"The distance between the layers of two neural networks.","title":"layers_distance"},{"location":"temp/bayesian/#skip_connection_distance","text":"The distance between two skip-connections.","title":"skip_connection_distance"},{"location":"temp/bayesian/#skip_connections_distance","text":"The distance between the skip-connections of two neural networks.","title":"skip_connections_distance"},{"location":"temp/bayesian/#edit_distance","text":"The distance between two neural networks. Args: x: An instance of NetworkDescriptor. y: An instance of NetworkDescriptor","title":"edit_distance"},{"location":"temp/bayesian/#returns","text":"","title":"Returns"},{"location":"temp/bayesian/#edit_distance_matrix","text":"Calculate the edit distance.","title":"edit_distance_matrix"},{"location":"temp/bayesian/#args","text":"train_x : A list of neural architectures. train_y : A list of neural architectures.","title":"Args"},{"location":"temp/bayesian/#returns_1","text":"","title":"Returns"},{"location":"temp/bayesian/#vector_distance","text":"The Euclidean distance between two vectors.","title":"vector_distance"},{"location":"temp/bayesian/#bourgain_embedding_matrix","text":"Use Bourgain algorithm to embed the neural architectures based on their edit-distance.","title":"bourgain_embedding_matrix"},{"location":"temp/bayesian/#args_1","text":"distance_matrix : A matrix of edit-distances.","title":"Args"},{"location":"temp/bayesian/#returns_2","text":"","title":"Returns"},{"location":"temp/bayesian/#contain","text":"Check if the target descriptor is in the descriptors.","title":"contain"},{"location":"temp/bayesian/#incrementalgaussianprocess","text":"Gaussian process regressor.","title":"IncrementalGaussianProcess"},{"location":"temp/bayesian/#attributes","text":"alpha : A hyperparameter.","title":"Attributes"},{"location":"temp/bayesian/#fit","text":"Fit the regressor with more data.","title":"fit"},{"location":"temp/bayesian/#args_2","text":"train_x : A list of NetworkDescriptor. train_y : A list of metric values.","title":"Args"},{"location":"temp/bayesian/#incremental_fit","text":"Incrementally fit the regressor.","title":"incremental_fit"},{"location":"temp/bayesian/#first_fit","text":"Fit the regressor for the first time.","title":"first_fit"},{"location":"temp/bayesian/#predict","text":"Predict the result.","title":"predict"},{"location":"temp/bayesian/#args_3","text":"train_x : A list of NetworkDescriptor.","title":"Args"},{"location":"temp/bayesian/#returns_3","text":"y_mean : The predicted mean. y_std : The predicted standard deviation.","title":"Returns"},{"location":"temp/bayesian/#bayesianoptimizer","text":"A Bayesian optimizer for neural architectures.","title":"BayesianOptimizer"},{"location":"temp/bayesian/#attributes_1","text":"searcher : The Searcher which is calling the Bayesian optimizer. t_min : The minimum temperature for simulated annealing. metric : An instance of the Metric subclasses. gpr : A GaussianProcessRegressor for bayesian optimization. beta : The beta in acquisition function. (refer to our paper) search_tree : The network morphism search tree.","title":"Attributes"},{"location":"temp/bayesian/#fit_1","text":"Fit the optimizer with new architectures and performances.","title":"fit"},{"location":"temp/bayesian/#args_4","text":"x_queue : A list of NetworkDescriptor. y_queue : A list of metric values.","title":"Args"},{"location":"temp/bayesian/#generate","text":"Generate new architecture.","title":"generate"},{"location":"temp/bayesian/#args_5","text":"descriptors : All the searched neural architectures. timeout : An integer. The time limit in seconds. sync_message : the Queue for multiprocessing return value.","title":"Args"},{"location":"temp/bayesian/#returns_4","text":"graph : An instance of Graph. A morphed neural network with weights. father_id : The father node ID in the search tree.","title":"Returns"},{"location":"temp/bayesian/#elem","text":"Elements to be sorted according to metric value.","title":"Elem"},{"location":"temp/bayesian/#reverseelem","text":"Elements to be reversely sorted according to metric value.","title":"ReverseElem"},{"location":"temp/bayesian/#searchtree","text":"The network morphism search tree.","title":"SearchTree"},{"location":"temp/bayesian/#get_dict","text":"A recursive function to return the content of the tree in a dict.","title":"get_dict"},{"location":"temp/constant/","text":"","title":"Constant"},{"location":"temp/contribute/","text":"Contributing Guide Contributions are welcome, and greatly appreciated! Every little bit helps, and credit will always be given. We recommend you to check our Developer Tools Guide to make the development process easier and standard. Notably, you can follow the tag of call for contributors in the issues. Those issues are designed for the external contributors to solve. The pull requests solving these issues are most likely to be merged. There are many ways to contribute to Auto-Keras, including submit feedback, fix bugs, implement features, and write documentation. The guide for each type of contribution is as follows. Submit Feedback The feedback should be submitted by creating an issue at GitHub issues . Select the related template (bug report, feature request, or custom) and add the corresponding labels. Fix Bugs: You may look through the GitHub issues for bugs. Anything tagged with \"bug report\" is open to whoever wants to implement it. Please follow the Pull Request Guide to submit your pull request. Please also read Code Style Guide , and Documentation Guide to ensure your merge request meet our requirements. Implement Features You may look through the GitHub issues for feature requests. Anything tagged with \"feature request\" is open to whoever wants to implement it. Please follow the Pull Request Guide to submit your pull request. Please also read Code Style Guide , Documentation Guide , and Testing Guide to ensure your merge request meet our requirements. Write Documentation The documentation of Auto-Keras is either directly written into the Markdown files in mkdocs directory , or automatically extracted from the docstrings by executing the autogen.py . In the first situation, you only need to change the markdown file. In the second situation, you need to change the docstrings and execute autogen.py to update the Markdown files. Please follow the Pull Request Guide to submit your pull request. Please also read Documentation Guide to ensure your merge request meet our requirements. Pull Request Guide Before you submit a pull request, check that it meets these guidelines: Fork the repository. Create a new branch from the master branch. Give your new branch a meaningful name. Pull request from your new branch to the master branch of the original autokeras repo. Give your pull request a meaningful name. Include \"resolves #issue_number\" in the description of the pull request and briefly describe your contribution. Submit the pull request from the first day of your development (after your first commit) and prefix the title of the pull request with [WIP] . When the contribution is complete, make sure the pull request passed the CI tests. Change the [WIP] to [MRG] . Set the reviewer to @jhfjhfj1 . For the case of bug fixes, add new test cases which would fail before your bug fix. If you are a collaborator of the autokeras repo, you don't need to fork the repository. Just create a new branch directly. You also need to change the assignee to the reviewer when request for code review. The reviewer will change the assignee back to you when finished the review. The assignee always means who should push the progress of the pull request now. Code Style Guide This project tries to closely follow the official Python Style Guide detailed in PEP8 . The docstrings follow the Google Python Style Guide . Please follow these style guide closely, especially for the docstrings, which would be extracted automatically to generate the documentation. Documentation Guide: The documentation should be provided in two ways, docstring, tutorial, and readme file. We prefer the documentation to be as complete as possible. Docstring All the methods and classes may directly be called by the user need to be documented with docstrings. The docstrings should contain all the fields required by the Google Python Style Guide . Tutorial You only need to add tutorials to your code if you are contributing or updating a new task module, e.g. TextClassifier, VideoClassifier, or a new function could be directly called by the user. You can modify mkdocs/docs/start.md to add your tutorial. The code example of your new task module should be added to the examples directory. Readme File You only need to add tutorials to your code if you are contributing or updating a new task module, e.g. TextClassifier, VideoClassifier. The readme file should be named as README.md . It should be written in Markdown. The content should contain your name, affiliation, and any reference to the method you use. Testing Guide Pytest is used to write the unit tests of Auto-Keras. You should test your code by writing unit testing code in tests directory. The testing file name should be the .py file with a prefix of test_ in the corresponding directory, e.g., the name should be test_layers.py if the code of which is to test layer.py . The tests should be run in the root directory of the project by executing the cov.sh file. It would output the coverage information into a directory named htmlcov . Please make sure the code coverage percentage does not decrease after your contribution, otherwise, the code will not be merged. Developer Tools Guide We highly recommend you to use Pycharm and virtualenvwrapper . Pycharm Pycharm is the best IDE for large project development in Python. We recommend you inspect the code before you pull request to fix any error and warning suggested by the inspection. Virtualenvwrapper Virtualenvwrapper is a tool to build separated Python environment for each project. In this way, you can install a different version of Tensorflow, Pytorch, or any other package for each project. We recommend you to create a virtualenv for autokeras development with virtualenvwrapper, and only install the packages required by autokeras with the corresponding version. The virtualenv should be created based on Python 3.6 interpreter. Use pycharm to select the virtualenv as interpreter . Reusable Code Guide You may checkout this code review video to get familiar with the code structure. Other than the base classes you have to extend, there are some other classes you can extend. ModelTrainer autokeras.model_trainer.ModelTrainer is a class for training Pytorch models. If needed a new metric or loss function other than the ones we have, you can add your own to loss_function.py and metric.py . You can follow its documentation and this example to use it. Make sure your loss function, metric, Pytorch model, and Dataloader are compatible with each other. Main Contributor List We really appreciate all the contributions. To show our appreciation to those who contributed most, we would like to maintain a list of main contributors. To be in the list, you need to meet the following requirments. 1. Be on campus of Texas A&M University. 2. Constantly present in our meetings. 3. Constantly contribute code to our repository. 4. Keep the above for over 6 months.","title":"Contributing Guide"},{"location":"temp/contribute/#contributing-guide","text":"Contributions are welcome, and greatly appreciated! Every little bit helps, and credit will always be given. We recommend you to check our Developer Tools Guide to make the development process easier and standard. Notably, you can follow the tag of call for contributors in the issues. Those issues are designed for the external contributors to solve. The pull requests solving these issues are most likely to be merged. There are many ways to contribute to Auto-Keras, including submit feedback, fix bugs, implement features, and write documentation. The guide for each type of contribution is as follows.","title":"Contributing Guide"},{"location":"temp/contribute/#submit-feedback","text":"The feedback should be submitted by creating an issue at GitHub issues . Select the related template (bug report, feature request, or custom) and add the corresponding labels.","title":"Submit Feedback"},{"location":"temp/contribute/#fix-bugs","text":"You may look through the GitHub issues for bugs. Anything tagged with \"bug report\" is open to whoever wants to implement it. Please follow the Pull Request Guide to submit your pull request. Please also read Code Style Guide , and Documentation Guide to ensure your merge request meet our requirements.","title":"Fix Bugs:"},{"location":"temp/contribute/#implement-features","text":"You may look through the GitHub issues for feature requests. Anything tagged with \"feature request\" is open to whoever wants to implement it. Please follow the Pull Request Guide to submit your pull request. Please also read Code Style Guide , Documentation Guide , and Testing Guide to ensure your merge request meet our requirements.","title":"Implement Features"},{"location":"temp/contribute/#write-documentation","text":"The documentation of Auto-Keras is either directly written into the Markdown files in mkdocs directory , or automatically extracted from the docstrings by executing the autogen.py . In the first situation, you only need to change the markdown file. In the second situation, you need to change the docstrings and execute autogen.py to update the Markdown files. Please follow the Pull Request Guide to submit your pull request. Please also read Documentation Guide to ensure your merge request meet our requirements.","title":"Write Documentation"},{"location":"temp/contribute/#pull-request-guide","text":"Before you submit a pull request, check that it meets these guidelines: Fork the repository. Create a new branch from the master branch. Give your new branch a meaningful name. Pull request from your new branch to the master branch of the original autokeras repo. Give your pull request a meaningful name. Include \"resolves #issue_number\" in the description of the pull request and briefly describe your contribution. Submit the pull request from the first day of your development (after your first commit) and prefix the title of the pull request with [WIP] . When the contribution is complete, make sure the pull request passed the CI tests. Change the [WIP] to [MRG] . Set the reviewer to @jhfjhfj1 . For the case of bug fixes, add new test cases which would fail before your bug fix. If you are a collaborator of the autokeras repo, you don't need to fork the repository. Just create a new branch directly. You also need to change the assignee to the reviewer when request for code review. The reviewer will change the assignee back to you when finished the review. The assignee always means who should push the progress of the pull request now.","title":"Pull Request Guide"},{"location":"temp/contribute/#code-style-guide","text":"This project tries to closely follow the official Python Style Guide detailed in PEP8 . The docstrings follow the Google Python Style Guide . Please follow these style guide closely, especially for the docstrings, which would be extracted automatically to generate the documentation.","title":"Code Style Guide"},{"location":"temp/contribute/#documentation-guide","text":"The documentation should be provided in two ways, docstring, tutorial, and readme file. We prefer the documentation to be as complete as possible.","title":"Documentation Guide:"},{"location":"temp/contribute/#docstring","text":"All the methods and classes may directly be called by the user need to be documented with docstrings. The docstrings should contain all the fields required by the Google Python Style Guide .","title":"Docstring"},{"location":"temp/contribute/#tutorial","text":"You only need to add tutorials to your code if you are contributing or updating a new task module, e.g. TextClassifier, VideoClassifier, or a new function could be directly called by the user. You can modify mkdocs/docs/start.md to add your tutorial. The code example of your new task module should be added to the examples directory.","title":"Tutorial"},{"location":"temp/contribute/#readme-file","text":"You only need to add tutorials to your code if you are contributing or updating a new task module, e.g. TextClassifier, VideoClassifier. The readme file should be named as README.md . It should be written in Markdown. The content should contain your name, affiliation, and any reference to the method you use.","title":"Readme File"},{"location":"temp/contribute/#testing-guide","text":"Pytest is used to write the unit tests of Auto-Keras. You should test your code by writing unit testing code in tests directory. The testing file name should be the .py file with a prefix of test_ in the corresponding directory, e.g., the name should be test_layers.py if the code of which is to test layer.py . The tests should be run in the root directory of the project by executing the cov.sh file. It would output the coverage information into a directory named htmlcov . Please make sure the code coverage percentage does not decrease after your contribution, otherwise, the code will not be merged.","title":"Testing Guide"},{"location":"temp/contribute/#developer-tools-guide","text":"We highly recommend you to use Pycharm and virtualenvwrapper .","title":"Developer Tools Guide"},{"location":"temp/contribute/#pycharm","text":"Pycharm is the best IDE for large project development in Python. We recommend you inspect the code before you pull request to fix any error and warning suggested by the inspection.","title":"Pycharm"},{"location":"temp/contribute/#virtualenvwrapper","text":"Virtualenvwrapper is a tool to build separated Python environment for each project. In this way, you can install a different version of Tensorflow, Pytorch, or any other package for each project. We recommend you to create a virtualenv for autokeras development with virtualenvwrapper, and only install the packages required by autokeras with the corresponding version. The virtualenv should be created based on Python 3.6 interpreter. Use pycharm to select the virtualenv as interpreter .","title":"Virtualenvwrapper"},{"location":"temp/contribute/#reusable-code-guide","text":"You may checkout this code review video to get familiar with the code structure. Other than the base classes you have to extend, there are some other classes you can extend.","title":"Reusable Code Guide"},{"location":"temp/contribute/#modeltrainer","text":"autokeras.model_trainer.ModelTrainer is a class for training Pytorch models. If needed a new metric or loss function other than the ones we have, you can add your own to loss_function.py and metric.py . You can follow its documentation and this example to use it. Make sure your loss function, metric, Pytorch model, and Dataloader are compatible with each other.","title":"ModelTrainer"},{"location":"temp/contribute/#main-contributor-list","text":"We really appreciate all the contributions. To show our appreciation to those who contributed most, we would like to maintain a list of main contributors. To be in the list, you need to meet the following requirments. 1. Be on campus of Texas A&M University. 2. Constantly present in our meetings. 3. Constantly contribute code to our repository. 4. Keep the above for over 6 months.","title":"Main Contributor List"},{"location":"temp/custom_queue/","text":"SharedCounter A synchronized shared counter. The locking done by multiprocessing.Value ensures that only a single process or thread may read or write the in-memory ctypes object. However, in order to do n += 1, Python performs a read followed by a write, so a second process may read the old value before the new one is written by the first process. The solution is to use a multiprocessing.Lock to guarantee the atomicity of the modifications to Value. This class comes almost entirely from Eli Bendersky's blog: http://eli.thegreenplace.net/2012/01/04/shared-counter-with-pythons-multiprocessing/ increment Increment the counter by n (default = 1) value Return the value of the counter Queue A portable implementation of multiprocessing.Queue. Because of multithreading / multiprocessing semantics, Queue.qsize() may raise the NotImplementedError exception on Unix platforms like Mac OS X where sem_getvalue() is not implemented. This subclass addresses this problem by using a synchronized shared counter (initialized to zero) and increasing / decreasing its value every time the put() and get() methods are called, respectively. This not only prevents NotImplementedError from being raised, but also allows us to implement a reliable version of both qsize() and empty(). qsize Reliable implementation of multiprocessing.Queue.qsize() empty Reliable implementation of multiprocessing.Queue.empty()","title":"Custom queue"},{"location":"temp/custom_queue/#sharedcounter","text":"A synchronized shared counter. The locking done by multiprocessing.Value ensures that only a single process or thread may read or write the in-memory ctypes object. However, in order to do n += 1, Python performs a read followed by a write, so a second process may read the old value before the new one is written by the first process. The solution is to use a multiprocessing.Lock to guarantee the atomicity of the modifications to Value. This class comes almost entirely from Eli Bendersky's blog: http://eli.thegreenplace.net/2012/01/04/shared-counter-with-pythons-multiprocessing/","title":"SharedCounter"},{"location":"temp/custom_queue/#increment","text":"Increment the counter by n (default = 1)","title":"increment"},{"location":"temp/custom_queue/#value","text":"Return the value of the counter","title":"value"},{"location":"temp/custom_queue/#queue","text":"A portable implementation of multiprocessing.Queue. Because of multithreading / multiprocessing semantics, Queue.qsize() may raise the NotImplementedError exception on Unix platforms like Mac OS X where sem_getvalue() is not implemented. This subclass addresses this problem by using a synchronized shared counter (initialized to zero) and increasing / decreasing its value every time the put() and get() methods are called, respectively. This not only prevents NotImplementedError from being raised, but also allows us to implement a reliable version of both qsize() and empty().","title":"Queue"},{"location":"temp/custom_queue/#qsize","text":"Reliable implementation of multiprocessing.Queue.qsize()","title":"qsize"},{"location":"temp/custom_queue/#empty","text":"Reliable implementation of multiprocessing.Queue.empty()","title":"empty"},{"location":"temp/data_transformer/","text":"ImageDataTransformer Perform basic image transformation and augmentation. Attributes max_val : the maximum value of all data. mean : the mean value. std : the standard deviation. augment : whether to perform augmentation on data. transform_train Transform the training data, perform random cropping data augmentation and basic random flip augmentation. Args data : Numpy array. The data to be transformed. batch_size : int batch_size. targets : the target of training set. Returns transform_test Transform the test data, perform normalization. Args data : Numpy array. The data to be transformed. batch_size : int batch_size. targets : the target of test set. Returns _transform Perform the actual transformation. Args compose_list : a list of transforming operation. data : x. targets : y. Returns MultiTransformDataset A class incorporate all transform method into a torch.Dataset class. Cutout Randomly mask out one or more patches from an image. Args n_holes (int) : Number of patches to cut out of each image. length (int) : The length (in pixels) of each square patch. call Perform the actual transformation. Args img (Tensor) : Tensor image of size (C, H, W). Returns Tensor : Image with n_holes of dimension length x length cut out of it.","title":"Data transformer"},{"location":"temp/data_transformer/#imagedatatransformer","text":"Perform basic image transformation and augmentation.","title":"ImageDataTransformer"},{"location":"temp/data_transformer/#attributes","text":"max_val : the maximum value of all data. mean : the mean value. std : the standard deviation. augment : whether to perform augmentation on data.","title":"Attributes"},{"location":"temp/data_transformer/#transform_train","text":"Transform the training data, perform random cropping data augmentation and basic random flip augmentation.","title":"transform_train"},{"location":"temp/data_transformer/#args","text":"data : Numpy array. The data to be transformed. batch_size : int batch_size. targets : the target of training set.","title":"Args"},{"location":"temp/data_transformer/#returns","text":"","title":"Returns"},{"location":"temp/data_transformer/#transform_test","text":"Transform the test data, perform normalization.","title":"transform_test"},{"location":"temp/data_transformer/#args_1","text":"data : Numpy array. The data to be transformed. batch_size : int batch_size. targets : the target of test set.","title":"Args"},{"location":"temp/data_transformer/#returns_1","text":"","title":"Returns"},{"location":"temp/data_transformer/#_transform","text":"Perform the actual transformation.","title":"_transform"},{"location":"temp/data_transformer/#args_2","text":"compose_list : a list of transforming operation. data : x. targets : y.","title":"Args"},{"location":"temp/data_transformer/#returns_2","text":"","title":"Returns"},{"location":"temp/data_transformer/#multitransformdataset","text":"A class incorporate all transform method into a torch.Dataset class.","title":"MultiTransformDataset"},{"location":"temp/data_transformer/#cutout","text":"Randomly mask out one or more patches from an image.","title":"Cutout"},{"location":"temp/data_transformer/#args_3","text":"n_holes (int) : Number of patches to cut out of each image. length (int) : The length (in pixels) of each square patch.","title":"Args"},{"location":"temp/data_transformer/#call","text":"Perform the actual transformation.","title":"call"},{"location":"temp/data_transformer/#args_4","text":"img (Tensor) : Tensor image of size (C, H, W).","title":"Args"},{"location":"temp/data_transformer/#returns_3","text":"Tensor : Image with n_holes of dimension length x length cut out of it.","title":"Returns"},{"location":"temp/gan/","text":"DCGAN Deep Convolution Generative Adversary Network init Args: nz: size of the latent z vector ngf: of gen filters in first conv layer ndf: of discrim filters in first conv layer nc: number of input chanel verbose: A boolean of whether the search process will be printed to stdout. gen_training_result: A tuple of (path, size) to denote where to output the intermediate result with size augment: A boolean value indicating whether the data needs augmentation. fit Train only Args x_train : ndarray contained the training data GANModelTrainer A ModelTrainer especially for the GAN. Attributes: d_model: A discriminator model. g_model: A generator model. out_f: Out file. out_size: Size of the output image. optimizer_d: Optimizer for discriminator. optimizer_g: Optimizer for generator. init Initialize the GANModelTrainer. Args: g_model: The generator model to be trained. d_model: The discriminator model to be trained. train_data: the training data. loss_function: The loss function for both discriminator and generator. verbose: Whether to output the system output. gen_training_result: Whether to generate the intermediate result while training. _train Perform the actual train.","title":"Gan"},{"location":"temp/gan/#dcgan","text":"Deep Convolution Generative Adversary Network","title":"DCGAN"},{"location":"temp/gan/#init","text":"Args: nz: size of the latent z vector ngf: of gen filters in first conv layer ndf: of discrim filters in first conv layer nc: number of input chanel verbose: A boolean of whether the search process will be printed to stdout. gen_training_result: A tuple of (path, size) to denote where to output the intermediate result with size augment: A boolean value indicating whether the data needs augmentation.","title":"init"},{"location":"temp/gan/#fit","text":"Train only","title":"fit"},{"location":"temp/gan/#args","text":"x_train : ndarray contained the training data","title":"Args"},{"location":"temp/gan/#ganmodeltrainer","text":"A ModelTrainer especially for the GAN. Attributes: d_model: A discriminator model. g_model: A generator model. out_f: Out file. out_size: Size of the output image. optimizer_d: Optimizer for discriminator. optimizer_g: Optimizer for generator.","title":"GANModelTrainer"},{"location":"temp/gan/#init_1","text":"Initialize the GANModelTrainer. Args: g_model: The generator model to be trained. d_model: The discriminator model to be trained. train_data: the training data. loss_function: The loss function for both discriminator and generator. verbose: Whether to output the system output. gen_training_result: Whether to generate the intermediate result while training.","title":"init"},{"location":"temp/gan/#_train","text":"Perform the actual train.","title":"_train"},{"location":"temp/generator/","text":"NetworkGenerator The base class for generating a network. It can be used to generate a CNN or Multi-Layer Perceptron. Attributes n_output_node : Number of output nodes in the network. input_shape : A tuple to represent the input shape. init Initialize the instance. Sets the parameters n_output_node and input_shape for the instance. Args n_output_node : An integer. Number of output nodes in the network. input_shape : A tuple. Input shape of the network. CnnGenerator A class to generate CNN. Attributes n_dim : len(self.input_shape) - 1 conv : A class that represents (n_dim-1) dimensional convolution. dropout : A class that represents (n_dim-1) dimensional dropout. global_avg_pooling : A class that represents (n_dim-1) dimensional Global Average Pooling. pooling : A class that represents (n_dim-1) dimensional pooling. batch_norm : A class that represents (n_dim-1) dimensional batch normalization. init Initialize the instance. Args n_output_node : An integer. Number of output nodes in the network. input_shape : A tuple. Input shape of the network. generate Generates a CNN. Args model_len : An integer. Number of convolutional layers. model_width : An integer. Number of filters for the convolutional layers. Returns MlpGenerator A class to generate Multi-Layer Perceptron. init Initialize the instance. Args n_output_node : An integer. Number of output nodes in the network. input_shape : A tuple. Input shape of the network. If it is 1D, ensure the value is appended by a comma in the tuple. generate Generates a Multi-Layer Perceptron. Args model_len : An integer. Number of hidden layers. model_width : An integer or a list of integers of length model_len . If it is a list, it represents the number of nodes in each hidden layer. If it is an integer, all hidden layers have nodes equal to this value. Returns","title":"generator"},{"location":"temp/generator/#networkgenerator","text":"The base class for generating a network. It can be used to generate a CNN or Multi-Layer Perceptron.","title":"NetworkGenerator"},{"location":"temp/generator/#attributes","text":"n_output_node : Number of output nodes in the network. input_shape : A tuple to represent the input shape.","title":"Attributes"},{"location":"temp/generator/#init","text":"Initialize the instance. Sets the parameters n_output_node and input_shape for the instance.","title":"init"},{"location":"temp/generator/#args","text":"n_output_node : An integer. Number of output nodes in the network. input_shape : A tuple. Input shape of the network.","title":"Args"},{"location":"temp/generator/#cnngenerator","text":"A class to generate CNN.","title":"CnnGenerator"},{"location":"temp/generator/#attributes_1","text":"n_dim : len(self.input_shape) - 1 conv : A class that represents (n_dim-1) dimensional convolution. dropout : A class that represents (n_dim-1) dimensional dropout. global_avg_pooling : A class that represents (n_dim-1) dimensional Global Average Pooling. pooling : A class that represents (n_dim-1) dimensional pooling. batch_norm : A class that represents (n_dim-1) dimensional batch normalization.","title":"Attributes"},{"location":"temp/generator/#init_1","text":"Initialize the instance.","title":"init"},{"location":"temp/generator/#args_1","text":"n_output_node : An integer. Number of output nodes in the network. input_shape : A tuple. Input shape of the network.","title":"Args"},{"location":"temp/generator/#generate","text":"Generates a CNN.","title":"generate"},{"location":"temp/generator/#args_2","text":"model_len : An integer. Number of convolutional layers. model_width : An integer. Number of filters for the convolutional layers.","title":"Args"},{"location":"temp/generator/#returns","text":"","title":"Returns"},{"location":"temp/generator/#mlpgenerator","text":"A class to generate Multi-Layer Perceptron.","title":"MlpGenerator"},{"location":"temp/generator/#init_2","text":"Initialize the instance.","title":"init"},{"location":"temp/generator/#args_3","text":"n_output_node : An integer. Number of output nodes in the network. input_shape : A tuple. Input shape of the network. If it is 1D, ensure the value is appended by a comma in the tuple.","title":"Args"},{"location":"temp/generator/#generate_1","text":"Generates a Multi-Layer Perceptron.","title":"generate"},{"location":"temp/generator/#args_4","text":"model_len : An integer. Number of hidden layers. model_width : An integer or a list of integers of length model_len . If it is a list, it represents the number of nodes in each hidden layer. If it is an integer, all hidden layers have nodes equal to this value.","title":"Args"},{"location":"temp/generator/#returns_1","text":"","title":"Returns"},{"location":"temp/graph/","text":"NetworkDescriptor A class describing the neural architecture for neural network kernel. It only record the width of convolutional and dense layers, and the skip-connection types and positions. add_skip_connection Add a skip-connection to the descriptor. Args u : Number of convolutional layers before the starting point. v : Number of convolutional layers before the ending point. connection_type : Must be either CONCAT_CONNECT or ADD_CONNECT. Node A class for intermediate output tensor (node) in the Graph. Attributes shape : A tuple describing the shape of the tensor. Graph A class representing the neural architecture graph of a Keras model. Graph extracts the neural architecture graph from a Keras model. Each node in the graph is a intermediate tensor between layers. Each layer is an edge in the graph. Notably, multiple edges may refer to the same layer. (e.g. Add layer is adding two tensor into one tensor. So it is related to two edges.) Attributes input_shape : A tuple describing the input tensor shape, not including the number of instances. weighted : A boolean marking if there are actual values in the weights of the layers. Sometime we only need the neural architecture information with a graph. In that case, we do not save the weights to save memory and time. node_list : A list of integers. The indices of the list are the identifiers. layer_list : A list of stub layers. The indices of the list are the identifiers. node_to_id : A dict instance mapping from node integers to their identifiers. layer_to_id : A dict instance mapping from stub layers to their identifiers. layer_id_to_input_node_ids : A dict instance mapping from layer identifiers to their input nodes identifiers. layer_id_to_output_node_ids : A dict instance mapping from layer identifiers to their output nodes identifiers. adj_list : A two dimensional list. The adjacency list of the graph. The first dimension is identified by tensor identifiers. In each edge list, the elements are two-element tuples of (tensor identifier, layer identifier). reverse_adj_list : A reverse adjacent list in the same format as adj_list. operation_history : A list saving all the network morphism operations. n_dim : An integer. If it uses Conv1d, n_dim should be 1. vis : A dictionary of temporary storage for whether an local operation has been done during the network morphism. init Initializer for Graph. Args input_shape : A tuple describing the input tensor shape, not including the number of instances. weighted : A boolean marking if there are actual values in the weights of the layers. Sometime we only need the neural architecture information with a graph. In that case, we do not save the weights to save memory and time. add_layer Add a layer to the Graph. Args layer : An instance of the subclasses of StubLayer in layers.py. input_node_id : An integer. The ID of the input node of the layer. Returns output_node_id : An integer. The ID of the output node of the layer. n_nodes Return the number of nodes in the model. n_layers Return the number of layers in the model. _add_node Add a new node to node_list and give the node an ID. Args node : An instance of Node. Returns node_id : An integer. _add_edge Add a new layer to the graph. The nodes should be created in advance. _redirect_edge Redirect the layer to a new node. Change the edge originally from u_id to v_id into an edge from u_id to new_v_id while keeping all other property of the edge the same. _replace_layer Replace the layer with a new layer. topological_order Return the topological order of the node IDs from the input node to the output node. _get_pooling_layers Given two node IDs, return all the pooling layers between them. _depth_first_search Search for all the layers and nodes down the path. A recursive function to search all the layers and nodes between the node in the node_list and the node with target_id. _search Search the graph for all the layers to be widened caused by an operation. It is an recursive function with duplication check to avoid deadlock. It searches from a starting node u until the corresponding layers has been widened. Args u : The starting node ID. start_dim : The position to insert the additional dimensions. total_dim : The total number of dimensions the layer has before widening. n_add : The number of dimensions to add. to_deeper_model Insert a relu-conv-bn block after the target block. Args target_id : A convolutional layer ID. The new block should be inserted after the block. new_layer : An instance of StubLayer subclasses. to_wider_model Widen the last dimension of the output of the pre_layer. Args pre_layer_id : The ID of a convolutional layer or dense layer. n_add : The number of dimensions to add. _insert_new_layers Insert the new_layers after the node with start_node_id. to_add_skip_model Add a weighted add skip-connection from after start node to end node. Args start_id : The convolutional layer ID, after which to start the skip-connection. end_id : The convolutional layer ID, after which to end the skip-connection. to_concat_skip_model Add a weighted add concatenate connection from after start node to end node. Args start_id : The convolutional layer ID, after which to start the skip-connection. end_id : The convolutional layer ID, after which to end the skip-connection. extract_descriptor Extract the the description of the Graph as an instance of NetworkDescriptor. produce_model Build a new torch model based on the current graph. get_main_chain_layers Return a list of layer IDs in the main chain. get_main_chain Returns the main chain node ID list.","title":"graph"},{"location":"temp/graph/#networkdescriptor","text":"A class describing the neural architecture for neural network kernel. It only record the width of convolutional and dense layers, and the skip-connection types and positions.","title":"NetworkDescriptor"},{"location":"temp/graph/#add_skip_connection","text":"Add a skip-connection to the descriptor.","title":"add_skip_connection"},{"location":"temp/graph/#args","text":"u : Number of convolutional layers before the starting point. v : Number of convolutional layers before the ending point. connection_type : Must be either CONCAT_CONNECT or ADD_CONNECT.","title":"Args"},{"location":"temp/graph/#node","text":"A class for intermediate output tensor (node) in the Graph.","title":"Node"},{"location":"temp/graph/#attributes","text":"shape : A tuple describing the shape of the tensor.","title":"Attributes"},{"location":"temp/graph/#graph","text":"A class representing the neural architecture graph of a Keras model. Graph extracts the neural architecture graph from a Keras model. Each node in the graph is a intermediate tensor between layers. Each layer is an edge in the graph. Notably, multiple edges may refer to the same layer. (e.g. Add layer is adding two tensor into one tensor. So it is related to two edges.)","title":"Graph"},{"location":"temp/graph/#attributes_1","text":"input_shape : A tuple describing the input tensor shape, not including the number of instances. weighted : A boolean marking if there are actual values in the weights of the layers. Sometime we only need the neural architecture information with a graph. In that case, we do not save the weights to save memory and time. node_list : A list of integers. The indices of the list are the identifiers. layer_list : A list of stub layers. The indices of the list are the identifiers. node_to_id : A dict instance mapping from node integers to their identifiers. layer_to_id : A dict instance mapping from stub layers to their identifiers. layer_id_to_input_node_ids : A dict instance mapping from layer identifiers to their input nodes identifiers. layer_id_to_output_node_ids : A dict instance mapping from layer identifiers to their output nodes identifiers. adj_list : A two dimensional list. The adjacency list of the graph. The first dimension is identified by tensor identifiers. In each edge list, the elements are two-element tuples of (tensor identifier, layer identifier). reverse_adj_list : A reverse adjacent list in the same format as adj_list. operation_history : A list saving all the network morphism operations. n_dim : An integer. If it uses Conv1d, n_dim should be 1. vis : A dictionary of temporary storage for whether an local operation has been done during the network morphism.","title":"Attributes"},{"location":"temp/graph/#init","text":"Initializer for Graph.","title":"init"},{"location":"temp/graph/#args_1","text":"input_shape : A tuple describing the input tensor shape, not including the number of instances. weighted : A boolean marking if there are actual values in the weights of the layers. Sometime we only need the neural architecture information with a graph. In that case, we do not save the weights to save memory and time.","title":"Args"},{"location":"temp/graph/#add_layer","text":"Add a layer to the Graph.","title":"add_layer"},{"location":"temp/graph/#args_2","text":"layer : An instance of the subclasses of StubLayer in layers.py. input_node_id : An integer. The ID of the input node of the layer.","title":"Args"},{"location":"temp/graph/#returns","text":"output_node_id : An integer. The ID of the output node of the layer.","title":"Returns"},{"location":"temp/graph/#n_nodes","text":"Return the number of nodes in the model.","title":"n_nodes"},{"location":"temp/graph/#n_layers","text":"Return the number of layers in the model.","title":"n_layers"},{"location":"temp/graph/#_add_node","text":"Add a new node to node_list and give the node an ID.","title":"_add_node"},{"location":"temp/graph/#args_3","text":"node : An instance of Node.","title":"Args"},{"location":"temp/graph/#returns_1","text":"node_id : An integer.","title":"Returns"},{"location":"temp/graph/#_add_edge","text":"Add a new layer to the graph. The nodes should be created in advance.","title":"_add_edge"},{"location":"temp/graph/#_redirect_edge","text":"Redirect the layer to a new node. Change the edge originally from u_id to v_id into an edge from u_id to new_v_id while keeping all other property of the edge the same.","title":"_redirect_edge"},{"location":"temp/graph/#_replace_layer","text":"Replace the layer with a new layer.","title":"_replace_layer"},{"location":"temp/graph/#topological_order","text":"Return the topological order of the node IDs from the input node to the output node.","title":"topological_order"},{"location":"temp/graph/#_get_pooling_layers","text":"Given two node IDs, return all the pooling layers between them.","title":"_get_pooling_layers"},{"location":"temp/graph/#_depth_first_search","text":"Search for all the layers and nodes down the path. A recursive function to search all the layers and nodes between the node in the node_list and the node with target_id.","title":"_depth_first_search"},{"location":"temp/graph/#_search","text":"Search the graph for all the layers to be widened caused by an operation. It is an recursive function with duplication check to avoid deadlock. It searches from a starting node u until the corresponding layers has been widened.","title":"_search"},{"location":"temp/graph/#args_4","text":"u : The starting node ID. start_dim : The position to insert the additional dimensions. total_dim : The total number of dimensions the layer has before widening. n_add : The number of dimensions to add.","title":"Args"},{"location":"temp/graph/#to_deeper_model","text":"Insert a relu-conv-bn block after the target block.","title":"to_deeper_model"},{"location":"temp/graph/#args_5","text":"target_id : A convolutional layer ID. The new block should be inserted after the block. new_layer : An instance of StubLayer subclasses.","title":"Args"},{"location":"temp/graph/#to_wider_model","text":"Widen the last dimension of the output of the pre_layer.","title":"to_wider_model"},{"location":"temp/graph/#args_6","text":"pre_layer_id : The ID of a convolutional layer or dense layer. n_add : The number of dimensions to add.","title":"Args"},{"location":"temp/graph/#_insert_new_layers","text":"Insert the new_layers after the node with start_node_id.","title":"_insert_new_layers"},{"location":"temp/graph/#to_add_skip_model","text":"Add a weighted add skip-connection from after start node to end node.","title":"to_add_skip_model"},{"location":"temp/graph/#args_7","text":"start_id : The convolutional layer ID, after which to start the skip-connection. end_id : The convolutional layer ID, after which to end the skip-connection.","title":"Args"},{"location":"temp/graph/#to_concat_skip_model","text":"Add a weighted add concatenate connection from after start node to end node.","title":"to_concat_skip_model"},{"location":"temp/graph/#args_8","text":"start_id : The convolutional layer ID, after which to start the skip-connection. end_id : The convolutional layer ID, after which to end the skip-connection.","title":"Args"},{"location":"temp/graph/#extract_descriptor","text":"Extract the the description of the Graph as an instance of NetworkDescriptor.","title":"extract_descriptor"},{"location":"temp/graph/#produce_model","text":"Build a new torch model based on the current graph.","title":"produce_model"},{"location":"temp/graph/#get_main_chain_layers","text":"Return a list of layer IDs in the main chain.","title":"get_main_chain_layers"},{"location":"temp/graph/#get_main_chain","text":"Returns the main chain node ID list.","title":"get_main_chain"},{"location":"temp/image_supervised/","text":"_image_to_array Read the image from the path and return it as an numpy.ndarray. Load the image file as an array Args img_path : a string whose value is the image file name read_images Read the images from the path and return their numpy.ndarray instances. Args img_file_names : List of strings representing image file names. # DEVELOPERS THERE'S PROBABLY A WAY TO MAKE THIS PARAM. OPTIONAL images_dir_path : Path to the directory containing images. parallel : (Default Returns x_train : a list of numpy.ndarrays containing the loaded images. load_image_dataset Load images from their files and load their labels from a csv file. Assumes the dataset is a set of images and the labels are in a CSV file. The CSV file should contain two columns whose names are 'File Name' and 'Label'. The file names in the first column should match the file names of the images with extensions, e.g., .jpg, .png. The path to the CSV file should be passed through the csv_file_path . The path to the directory containing all the images should be passed through image_path . Args csv_file_path : a string of the path to the CSV file images_path : a string of the path containing the directory of the images parallel : (Default Returns x : Four dimensional numpy.ndarray. The channel dimension is the last dimension. y : a numpy.ndarray of the labels for the images ImageSupervised Abstract image supervised class. Inherits from DeepTaskSupervised. Attributes path : A string of the path to the directory to save the classifier as well as intermediate results. cnn : CNN module from net_module.py. y_encoder : Label encoder, used in transform_y or inverse_transform_y for encode the label. For example, if one hot encoder needed, y_encoder can be OneHotEncoder. data_transformer : A transformer class to process the data. See example as ImageDataTransformer. verbose : A boolean value indicating the verbosity mode which determines whether the search process will be printed to stdout. augment : A boolean value indicating whether the data needs augmentation. If not define, then it will use the value of Constant.DATA_AUGMENTATION which is True by default. searcher_args : A dictionary containing the parameters for the searcher's init function. resize_shape : resize image height and width init Initialize the instance of the ImageSupervised class. The classifier will be loaded from the files in 'path' if parameter 'resume' is True. Otherwise it would create a new one. Args augment : A boolean value indicating whether the data needs augmentation. If not defined, then it will use the value of Constant.DATA_AUGMENTATION which is True by default. **kwargs : Needed for using the init () function of ImageSupervised's superclass verbose fit Find the best neural architecture for classifying the training data and train it. Based on the given dataset, the function will find the best neural architecture for it. The dataset must be in numpy.ndarray format. The training and validation data should be passed through x , y . This method will automatically split the training and validation data into training and validation sets. Args x : A numpy.ndarray instance containing the training data or the training data combined with the validation data. y : A numpy.ndarray instance containing the labels of the training data. or the label of the training data combined with the validation label. time_limit : The time limit for the search in seconds. (optional, default = None, which turns into 24 hours in method) cts : ImageClassifier ImageClassifier class. Inherits from ImageSupervised It is used for image classification. It searches convolutional neural network architectures for the best configuration for the image dataset. Attributes path : A string of the path to the directory to save the classifier as well as intermediate results. cnn : CNN module from net_module.py. y_encoder : Label encoder, used in transform_y or inverse_transform_y for encode the label. For example, if one hot encoder needed, y_encoder can be OneHotEncoder. data_transformer : A transformer class to process the data. See example as ImageDataTransformer. verbose : A boolean value indicating the verbosity mode which determines whether the search process will be printed to stdout. augment : A boolean value indicating whether the data needs augmentation. If not define, then it will use the value of Constant.DATA_AUGMENTATION which is True by default. searcher_args : A dictionary containing the parameters for the searcher's init function. resize_shape : resize image height and width transform_y Transform the parameter y_train using the variable self.y_encoder Args y : list of labels to convert inverse_transform_y Convert the encoded labels back to the original label space. Args output : list of labels to decode export_autokeras_model Creates and Exports the AutoKeras model to the given filename. Args model_file_name : A string containing the name of the file to which the model should be saved cts : ImageClassifier1D ImageClassifier1D class. It is used for 1D image classification. It searches convolutional neural network architectures for the best configuration for the 1D image dataset. ImageClassifier3D ImageClassifier3D class. It is used for 3D image classification. It searches convolutional neural network architectures for the best configuration for the 1D image dataset. ImageRegressor ImageRegressor class. It is used for image regression. It searches convolutional neural network architectures for the best configuration for the image dataset. export_autokeras_model Creates and Exports the AutoKeras model to the given filename. ImageRegressor1D ImageRegressor1D class. It is used for 1D image regression. It searches convolutional neural network architectures for the best configuration for the 1D image dataset. ImageRegressor3D ImageRegressor3D class. It is used for 3D image regression. It searches convolutional neural network architectures for the best configuration for the 1D image dataset. PortableImageSupervised init Initialize the instance. Args graph : The graph form of the learned model","title":"image_supervised"},{"location":"temp/image_supervised/#_image_to_array","text":"Read the image from the path and return it as an numpy.ndarray. Load the image file as an array","title":"_image_to_array"},{"location":"temp/image_supervised/#args","text":"img_path : a string whose value is the image file name","title":"Args"},{"location":"temp/image_supervised/#read_images","text":"Read the images from the path and return their numpy.ndarray instances.","title":"read_images"},{"location":"temp/image_supervised/#args_1","text":"img_file_names : List of strings representing image file names. # DEVELOPERS THERE'S PROBABLY A WAY TO MAKE THIS PARAM. OPTIONAL images_dir_path : Path to the directory containing images. parallel : (Default","title":"Args"},{"location":"temp/image_supervised/#returns","text":"x_train : a list of numpy.ndarrays containing the loaded images.","title":"Returns"},{"location":"temp/image_supervised/#load_image_dataset","text":"Load images from their files and load their labels from a csv file. Assumes the dataset is a set of images and the labels are in a CSV file. The CSV file should contain two columns whose names are 'File Name' and 'Label'. The file names in the first column should match the file names of the images with extensions, e.g., .jpg, .png. The path to the CSV file should be passed through the csv_file_path . The path to the directory containing all the images should be passed through image_path .","title":"load_image_dataset"},{"location":"temp/image_supervised/#args_2","text":"csv_file_path : a string of the path to the CSV file images_path : a string of the path containing the directory of the images parallel : (Default","title":"Args"},{"location":"temp/image_supervised/#returns_1","text":"x : Four dimensional numpy.ndarray. The channel dimension is the last dimension. y : a numpy.ndarray of the labels for the images","title":"Returns"},{"location":"temp/image_supervised/#imagesupervised","text":"Abstract image supervised class. Inherits from DeepTaskSupervised.","title":"ImageSupervised"},{"location":"temp/image_supervised/#attributes","text":"path : A string of the path to the directory to save the classifier as well as intermediate results. cnn : CNN module from net_module.py. y_encoder : Label encoder, used in transform_y or inverse_transform_y for encode the label. For example, if one hot encoder needed, y_encoder can be OneHotEncoder. data_transformer : A transformer class to process the data. See example as ImageDataTransformer. verbose : A boolean value indicating the verbosity mode which determines whether the search process will be printed to stdout. augment : A boolean value indicating whether the data needs augmentation. If not define, then it will use the value of Constant.DATA_AUGMENTATION which is True by default. searcher_args : A dictionary containing the parameters for the searcher's init function. resize_shape : resize image height and width","title":"Attributes"},{"location":"temp/image_supervised/#init","text":"Initialize the instance of the ImageSupervised class. The classifier will be loaded from the files in 'path' if parameter 'resume' is True. Otherwise it would create a new one.","title":"init"},{"location":"temp/image_supervised/#args_3","text":"augment : A boolean value indicating whether the data needs augmentation. If not defined, then it will use the value of Constant.DATA_AUGMENTATION which is True by default. **kwargs : Needed for using the init () function of ImageSupervised's superclass verbose","title":"Args"},{"location":"temp/image_supervised/#fit","text":"Find the best neural architecture for classifying the training data and train it. Based on the given dataset, the function will find the best neural architecture for it. The dataset must be in numpy.ndarray format. The training and validation data should be passed through x , y . This method will automatically split the training and validation data into training and validation sets.","title":"fit"},{"location":"temp/image_supervised/#args_4","text":"x : A numpy.ndarray instance containing the training data or the training data combined with the validation data. y : A numpy.ndarray instance containing the labels of the training data. or the label of the training data combined with the validation label. time_limit : The time limit for the search in seconds. (optional, default = None, which turns into 24 hours in method) cts :","title":"Args"},{"location":"temp/image_supervised/#imageclassifier","text":"ImageClassifier class. Inherits from ImageSupervised It is used for image classification. It searches convolutional neural network architectures for the best configuration for the image dataset.","title":"ImageClassifier"},{"location":"temp/image_supervised/#attributes_1","text":"path : A string of the path to the directory to save the classifier as well as intermediate results. cnn : CNN module from net_module.py. y_encoder : Label encoder, used in transform_y or inverse_transform_y for encode the label. For example, if one hot encoder needed, y_encoder can be OneHotEncoder. data_transformer : A transformer class to process the data. See example as ImageDataTransformer. verbose : A boolean value indicating the verbosity mode which determines whether the search process will be printed to stdout. augment : A boolean value indicating whether the data needs augmentation. If not define, then it will use the value of Constant.DATA_AUGMENTATION which is True by default. searcher_args : A dictionary containing the parameters for the searcher's init function. resize_shape : resize image height and width","title":"Attributes"},{"location":"temp/image_supervised/#transform_y","text":"Transform the parameter y_train using the variable self.y_encoder","title":"transform_y"},{"location":"temp/image_supervised/#args_5","text":"y : list of labels to convert","title":"Args"},{"location":"temp/image_supervised/#inverse_transform_y","text":"Convert the encoded labels back to the original label space.","title":"inverse_transform_y"},{"location":"temp/image_supervised/#args_6","text":"output : list of labels to decode","title":"Args"},{"location":"temp/image_supervised/#export_autokeras_model","text":"Creates and Exports the AutoKeras model to the given filename.","title":"export_autokeras_model"},{"location":"temp/image_supervised/#args_7","text":"model_file_name : A string containing the name of the file to which the model should be saved cts :","title":"Args"},{"location":"temp/image_supervised/#imageclassifier1d","text":"ImageClassifier1D class. It is used for 1D image classification. It searches convolutional neural network architectures for the best configuration for the 1D image dataset.","title":"ImageClassifier1D"},{"location":"temp/image_supervised/#imageclassifier3d","text":"ImageClassifier3D class. It is used for 3D image classification. It searches convolutional neural network architectures for the best configuration for the 1D image dataset.","title":"ImageClassifier3D"},{"location":"temp/image_supervised/#imageregressor","text":"ImageRegressor class. It is used for image regression. It searches convolutional neural network architectures for the best configuration for the image dataset.","title":"ImageRegressor"},{"location":"temp/image_supervised/#export_autokeras_model_1","text":"Creates and Exports the AutoKeras model to the given filename.","title":"export_autokeras_model"},{"location":"temp/image_supervised/#imageregressor1d","text":"ImageRegressor1D class. It is used for 1D image regression. It searches convolutional neural network architectures for the best configuration for the 1D image dataset.","title":"ImageRegressor1D"},{"location":"temp/image_supervised/#imageregressor3d","text":"ImageRegressor3D class. It is used for 3D image regression. It searches convolutional neural network architectures for the best configuration for the 1D image dataset.","title":"ImageRegressor3D"},{"location":"temp/image_supervised/#portableimagesupervised","text":"","title":"PortableImageSupervised"},{"location":"temp/image_supervised/#init_1","text":"Initialize the instance.","title":"init"},{"location":"temp/image_supervised/#args_8","text":"graph : The graph form of the learned model","title":"Args"},{"location":"temp/layer_transformer/","text":"","title":"Layer transformer"},{"location":"temp/layers/","text":"","title":"Layers"},{"location":"temp/loss_function/","text":"","title":"Loss function"},{"location":"temp/metric/","text":"","title":"Metric"},{"location":"temp/model/","text":"TorchModel A neural network class using pytorch constructed from an instance of Graph.","title":"Model"},{"location":"temp/model/#torchmodel","text":"A neural network class using pytorch constructed from an instance of Graph.","title":"TorchModel"},{"location":"temp/model_trainer/","text":"ModelTrainerBase A base class all model trainers will inherit from. Attributes: device: A string. Indicating the device to use. 'cuda' or 'cpu'. train_loader: Training data wrapped in batches in Pytorch Dataloader. test_loader: Testing data wrapped in batches in Pytorch Dataloader. loss_function: A function with two parameters (prediction, target). There is no specific requirement for the types of the parameters, as long as they are compatible with the model and the data loaders. The prediction should be the output of the model for a batch. The target should be a batch of targets packed in the data loaders. metric: It should be a subclass of class autokeras.metric.Metric. In the compute(prediction, target) function, prediction and targets are, all numpy arrays converted from the output of the model and the targets packed in the data loaders. verbose: Verbosity mode. train_model Train the model. Args: timeout: timeout in seconds max_iter_num: int, maximum numer of iteration max_no_improvement_num: after max_no_improvement_num, if the model still makes no improvement, finish training.","title":"model_trainer"},{"location":"temp/model_trainer/#modeltrainerbase","text":"A base class all model trainers will inherit from. Attributes: device: A string. Indicating the device to use. 'cuda' or 'cpu'. train_loader: Training data wrapped in batches in Pytorch Dataloader. test_loader: Testing data wrapped in batches in Pytorch Dataloader. loss_function: A function with two parameters (prediction, target). There is no specific requirement for the types of the parameters, as long as they are compatible with the model and the data loaders. The prediction should be the output of the model for a batch. The target should be a batch of targets packed in the data loaders. metric: It should be a subclass of class autokeras.metric.Metric. In the compute(prediction, target) function, prediction and targets are, all numpy arrays converted from the output of the model and the targets packed in the data loaders. verbose: Verbosity mode.","title":"ModelTrainerBase"},{"location":"temp/model_trainer/#train_model","text":"Train the model. Args: timeout: timeout in seconds max_iter_num: int, maximum numer of iteration max_no_improvement_num: after max_no_improvement_num, if the model still makes no improvement, finish training.","title":"train_model"},{"location":"temp/modeling/","text":"gelu Implementation of the gelu activation function. For information: OpenAI GPT's gelu is slightly different (and gives slightly different results): 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3)))) BertConfig Configuration class to store the configuration of a BertModel . init Constructs BertConfig. Args vocab_size_or_config_json_file : Vocabulary size of inputs_ids in BertModel . hidden_size : Size of the encoder layers and the pooler layer. num_hidden_layers : Number of hidden layers in the Transformer encoder. num_attention_heads : Number of attention heads for each attention layer in the Transformer encoder. intermediate_size : The size of the \"intermediate\" (i.e., feed-forward) layer in the Transformer encoder. hidden_act : The non-linear activation function (function or string) in the encoder and pooler. If string, \"gelu\", \"relu\" and \"swish\" are supported. hidden_dropout_prob : The dropout probabilitiy for all fully connected layers in the embeddings, encoder, and pooler. attention_probs_dropout_prob : The dropout ratio for the attention probabilities. max_position_embeddings : The maximum sequence length that this model might ever be used with. Typically set this to something large just in case (e.g., 512 or 1024 or 2048). type_vocab_size : The vocabulary size of the token_type_ids passed into BertModel . initializer_range : The sttdev of the truncated_normal_initializer for initializing all weight matrices. from_dict Constructs a BertConfig from a Python dictionary of parameters. from_json_file Constructs a BertConfig from a json file of parameters. to_dict Serializes this instance to a Python dictionary. to_json_string Serializes this instance to a JSON string. BertEmbeddings Construct the embeddings from word, position and token_type embeddings. PreTrainedBertModel An abstract class to handle weights initialization and a simple interface for dowloading and loading pretrained models. init_bert_weights Initialize the weights. from_pretrained Instantiate a PreTrainedBertModel from a pre-trained model file or a pytorch state dict. Download and cache the pre-trained model file if needed. Params: pretrained_model_name: either: - a str with the name of a pre-trained model to load selected in the list of: . bert-base-uncased . bert-large-uncased . bert-base-cased . bert-base-multilingual . bert-base-chinese - a path or url to a pretrained model archive containing: . bert_config.json a configuration file for the model . pytorch_model.bin a PyTorch dump of a BertForPreTraining instance cache_dir: an optional path to a folder in which the pre-trained models will be cached. state_dict: an optional state dictionnary (collections.OrderedDict object) to use instead of Google pre-trained models inputs, *kwargs: additional input for the specific Bert class (ex: num_labels for BertForSequenceClassification) BertModel BERT model (\"Bidirectional Embedding Representations from a Transformer\"). Params: config: a BertConfig class instance with the configuration to build a new model Inputs: input_ids : a torch.LongTensor of shape [batch_size, sequence_length] with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts extract_features.py , run_classifier.py and run_squad.py ) token_type_ids : an optional torch.LongTensor of shape [batch_size, sequence_length] with the token types indices selected in [0, 1]. Type 0 corresponds to a sentence A and type 1 corresponds to a sentence B token (see BERT paper for more details). attention_mask : an optional torch.LongTensor of shape [batch_size, sequence_length] with indices selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max input sequence length in the current batch. It's the mask that we typically use for attention when a batch has varying length sentences. output_all_encoded_layers : boolean which controls the content of the encoded_layers output as described below. Default: True . Outputs: Tuple of (encoded_layers, pooled_output) encoded_layers : controled by output_all_encoded_layers argument: - output_all_encoded_layers=True : outputs a list of the full sequences of encoded-hidden-states at the end of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size], - output_all_encoded_layers=False : outputs only the full sequence of hidden-states corresponding to the last attention block of shape [batch_size, sequence_length, hidden_size], pooled_output : a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a classifier pretrained on top of the hidden state associated to the first character of the input ( CLF ) to train on the Next-Sentence task (see BERT's paper). Example usage: python # Already been converted into WordPiece token ids input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]]) input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]]) token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]]) config = modeling.BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768, num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072) model = modeling.BertModel(config=config) all_encoder_layers, pooled_output = model(input_ids, token_type_ids, input_mask) BertForSupervisedTasks BERT model for supervised tasks such as classification or regression. This module is composed of the BERT model with a linear layer on top of the pooled output. Params: config : a BertConfig class instance with the configuration to build a new model. num_labels : the number of classes for the classifier. Default = 2. Required for classification. Inputs: input_ids : a torch.LongTensor of shape [batch_size, sequence_length] with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts extract_features.py , run_classifier.py and run_squad.py ) token_type_ids : an optional torch.LongTensor of shape [batch_size, sequence_length] with the token types indices selected in [0, 1]. Type 0 corresponds to a sentence A and type 1 corresponds to a sentence B token (see BERT paper for more details). attention_mask : an optional torch.LongTensor of shape [batch_size, sequence_length] with indices selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max input sequence length in the current batch. It's the mask that we typically use for attention when a batch has varying length sentences. labels : labels for the classification output: torch.LongTensor of shape [batch_size] with indices selected in [0, ..., num_labels]. Outputs: if labels is not None : Outputs the classification/regression loss of the output with the labels. if labels is None : Output of shape [batch_size, num_labels (or) 1].","title":"Modeling"},{"location":"temp/modeling/#gelu","text":"Implementation of the gelu activation function. For information: OpenAI GPT's gelu is slightly different (and gives slightly different results): 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))","title":"gelu"},{"location":"temp/modeling/#bertconfig","text":"Configuration class to store the configuration of a BertModel .","title":"BertConfig"},{"location":"temp/modeling/#init","text":"Constructs BertConfig.","title":"init"},{"location":"temp/modeling/#args","text":"vocab_size_or_config_json_file : Vocabulary size of inputs_ids in BertModel . hidden_size : Size of the encoder layers and the pooler layer. num_hidden_layers : Number of hidden layers in the Transformer encoder. num_attention_heads : Number of attention heads for each attention layer in the Transformer encoder. intermediate_size : The size of the \"intermediate\" (i.e., feed-forward) layer in the Transformer encoder. hidden_act : The non-linear activation function (function or string) in the encoder and pooler. If string, \"gelu\", \"relu\" and \"swish\" are supported. hidden_dropout_prob : The dropout probabilitiy for all fully connected layers in the embeddings, encoder, and pooler. attention_probs_dropout_prob : The dropout ratio for the attention probabilities. max_position_embeddings : The maximum sequence length that this model might ever be used with. Typically set this to something large just in case (e.g., 512 or 1024 or 2048). type_vocab_size : The vocabulary size of the token_type_ids passed into BertModel . initializer_range : The sttdev of the truncated_normal_initializer for initializing all weight matrices.","title":"Args"},{"location":"temp/modeling/#from_dict","text":"Constructs a BertConfig from a Python dictionary of parameters.","title":"from_dict"},{"location":"temp/modeling/#from_json_file","text":"Constructs a BertConfig from a json file of parameters.","title":"from_json_file"},{"location":"temp/modeling/#to_dict","text":"Serializes this instance to a Python dictionary.","title":"to_dict"},{"location":"temp/modeling/#to_json_string","text":"Serializes this instance to a JSON string.","title":"to_json_string"},{"location":"temp/modeling/#bertembeddings","text":"Construct the embeddings from word, position and token_type embeddings.","title":"BertEmbeddings"},{"location":"temp/modeling/#pretrainedbertmodel","text":"An abstract class to handle weights initialization and a simple interface for dowloading and loading pretrained models.","title":"PreTrainedBertModel"},{"location":"temp/modeling/#init_bert_weights","text":"Initialize the weights.","title":"init_bert_weights"},{"location":"temp/modeling/#from_pretrained","text":"Instantiate a PreTrainedBertModel from a pre-trained model file or a pytorch state dict. Download and cache the pre-trained model file if needed. Params: pretrained_model_name: either: - a str with the name of a pre-trained model to load selected in the list of: . bert-base-uncased . bert-large-uncased . bert-base-cased . bert-base-multilingual . bert-base-chinese - a path or url to a pretrained model archive containing: . bert_config.json a configuration file for the model . pytorch_model.bin a PyTorch dump of a BertForPreTraining instance cache_dir: an optional path to a folder in which the pre-trained models will be cached. state_dict: an optional state dictionnary (collections.OrderedDict object) to use instead of Google pre-trained models inputs, *kwargs: additional input for the specific Bert class (ex: num_labels for BertForSequenceClassification)","title":"from_pretrained"},{"location":"temp/modeling/#bertmodel","text":"BERT model (\"Bidirectional Embedding Representations from a Transformer\"). Params: config: a BertConfig class instance with the configuration to build a new model Inputs: input_ids : a torch.LongTensor of shape [batch_size, sequence_length] with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts extract_features.py , run_classifier.py and run_squad.py ) token_type_ids : an optional torch.LongTensor of shape [batch_size, sequence_length] with the token types indices selected in [0, 1]. Type 0 corresponds to a sentence A and type 1 corresponds to a sentence B token (see BERT paper for more details). attention_mask : an optional torch.LongTensor of shape [batch_size, sequence_length] with indices selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max input sequence length in the current batch. It's the mask that we typically use for attention when a batch has varying length sentences. output_all_encoded_layers : boolean which controls the content of the encoded_layers output as described below. Default: True . Outputs: Tuple of (encoded_layers, pooled_output) encoded_layers : controled by output_all_encoded_layers argument: - output_all_encoded_layers=True : outputs a list of the full sequences of encoded-hidden-states at the end of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size], - output_all_encoded_layers=False : outputs only the full sequence of hidden-states corresponding to the last attention block of shape [batch_size, sequence_length, hidden_size], pooled_output : a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a classifier pretrained on top of the hidden state associated to the first character of the input ( CLF ) to train on the Next-Sentence task (see BERT's paper). Example usage: python # Already been converted into WordPiece token ids input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]]) input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]]) token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]]) config = modeling.BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768, num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072) model = modeling.BertModel(config=config) all_encoder_layers, pooled_output = model(input_ids, token_type_ids, input_mask)","title":"BertModel"},{"location":"temp/modeling/#bertforsupervisedtasks","text":"BERT model for supervised tasks such as classification or regression. This module is composed of the BERT model with a linear layer on top of the pooled output. Params: config : a BertConfig class instance with the configuration to build a new model. num_labels : the number of classes for the classifier. Default = 2. Required for classification. Inputs: input_ids : a torch.LongTensor of shape [batch_size, sequence_length] with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts extract_features.py , run_classifier.py and run_squad.py ) token_type_ids : an optional torch.LongTensor of shape [batch_size, sequence_length] with the token types indices selected in [0, 1]. Type 0 corresponds to a sentence A and type 1 corresponds to a sentence B token (see BERT paper for more details). attention_mask : an optional torch.LongTensor of shape [batch_size, sequence_length] with indices selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max input sequence length in the current batch. It's the mask that we typically use for attention when a batch has varying length sentences. labels : labels for the classification output: torch.LongTensor of shape [batch_size] with indices selected in [0, ..., num_labels]. Outputs: if labels is not None : Outputs the classification/regression loss of the output with the labels. if labels is None : Output of shape [batch_size, num_labels (or) 1].","title":"BertForSupervisedTasks"},{"location":"temp/net_module/","text":"NetworkModule Class to create a network module. Attributes loss : A function taking two parameters, the predictions and the ground truth. metric : An instance of the Metric subclasses. searcher_args : A dictionary containing the parameters for the searcher's init function. searcher : An instance of the Searcher class. path : A string. The path to the directory to save the searcher. verbose : A boolean. Setting it to true prints to stdout. generators : A list of instances of the NetworkGenerator class or its subclasses. search_type : A constant denoting the type of hyperparameter search algorithm that must be used. fit Search the best network. Args n_output_node : A integer value represent the number of output node in the final layer. input_shape : A tuple to express the shape of every train entry. For example, MNIST dataset would be (28,28,1). train_data : A PyTorch DataLoader instance representing the training data. test_data : A PyTorch DataLoader instance representing the testing data. time_limit : A integer value represents the time limit on searching for models. final_fit Final training after found the best architecture. Args train_data : A DataLoader instance representing the training data. test_data : A DataLoader instance representing the testing data. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model. CnnModule Class to create a CNN module. MlpModule Class to create an MLP module.","title":"Net module"},{"location":"temp/net_module/#networkmodule","text":"Class to create a network module.","title":"NetworkModule"},{"location":"temp/net_module/#attributes","text":"loss : A function taking two parameters, the predictions and the ground truth. metric : An instance of the Metric subclasses. searcher_args : A dictionary containing the parameters for the searcher's init function. searcher : An instance of the Searcher class. path : A string. The path to the directory to save the searcher. verbose : A boolean. Setting it to true prints to stdout. generators : A list of instances of the NetworkGenerator class or its subclasses. search_type : A constant denoting the type of hyperparameter search algorithm that must be used.","title":"Attributes"},{"location":"temp/net_module/#fit","text":"Search the best network.","title":"fit"},{"location":"temp/net_module/#args","text":"n_output_node : A integer value represent the number of output node in the final layer. input_shape : A tuple to express the shape of every train entry. For example, MNIST dataset would be (28,28,1). train_data : A PyTorch DataLoader instance representing the training data. test_data : A PyTorch DataLoader instance representing the testing data. time_limit : A integer value represents the time limit on searching for models.","title":"Args"},{"location":"temp/net_module/#final_fit","text":"Final training after found the best architecture.","title":"final_fit"},{"location":"temp/net_module/#args_1","text":"train_data : A DataLoader instance representing the training data. test_data : A DataLoader instance representing the testing data. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model.","title":"Args"},{"location":"temp/net_module/#cnnmodule","text":"Class to create a CNN module.","title":"CnnModule"},{"location":"temp/net_module/#mlpmodule","text":"Class to create an MLP module.","title":"MlpModule"},{"location":"temp/net_transformer/","text":"","title":"Net transformer"},{"location":"temp/optimization/","text":"BertAdam Implements BERT version of Adam algorithm with weight decay fix. Params: lr: learning rate warmup: portion of t_total for the warmup, -1 means no warmup. Default: -1 t_total: total number of training steps for the learning rate schedule, -1 means constant learning rate. Default: -1 schedule: schedule to use for the warmup (see above). Default: 'warmup_linear' b1: Adams b1. Default: 0.9 b2: Adams b2. Default: 0.999 e: Adams epsilon. Default: 1e-6 weight_decay: Weight decay. Default: 0.01 max_grad_norm: Maximum norm for the gradients (-1 means no clipping). Default: 1.0 step Performs a single optimization step. Arguments: closure (callable, optional): A closure that reevaluates the model and returns the loss.","title":"Optimization"},{"location":"temp/optimization/#bertadam","text":"Implements BERT version of Adam algorithm with weight decay fix. Params: lr: learning rate warmup: portion of t_total for the warmup, -1 means no warmup. Default: -1 t_total: total number of training steps for the learning rate schedule, -1 means constant learning rate. Default: -1 schedule: schedule to use for the warmup (see above). Default: 'warmup_linear' b1: Adams b1. Default: 0.9 b2: Adams b2. Default: 0.999 e: Adams epsilon. Default: 1e-6 weight_decay: Weight decay. Default: 0.01 max_grad_norm: Maximum norm for the gradients (-1 means no clipping). Default: 1.0","title":"BertAdam"},{"location":"temp/optimization/#step","text":"Performs a single optimization step. Arguments: closure (callable, optional): A closure that reevaluates the model and returns the loss.","title":"step"},{"location":"temp/predefined_model/","text":"PredefinedModel The base class for the predefined model without architecture search Attributes graph : The graph form of the model. y_encoder : Label encoder, used in transform_y or inverse_transform_y for encode the label. For example, if one hot encoder needed, y_encoder can be OneHotEncoder. data_transformer : A instance of transformer to process the data, See example as ImageDataTransformer. verbose : A boolean of whether the search process will be printed to stdout. path : A string. The path to a directory, where the intermediate results are saved. _init_generator Initialize the generator to generate the model architecture. Args n_output_node : A integer value represent the number of output node in the final layer. input_shape : A tuple to express the shape of every train entry. fit Trains the model on the dataset given. Args x_train : A numpy.ndarray instance containing the training data, or the training data combined with the validation data. y_train : A numpy.ndarray instance containing the label of the training data, or the label of the training data combined with the validation label. time_limit : A dictionary containing the parameters of the ModelTrainer constructor.","title":"Predefined model"},{"location":"temp/predefined_model/#predefinedmodel","text":"The base class for the predefined model without architecture search","title":"PredefinedModel"},{"location":"temp/predefined_model/#attributes","text":"graph : The graph form of the model. y_encoder : Label encoder, used in transform_y or inverse_transform_y for encode the label. For example, if one hot encoder needed, y_encoder can be OneHotEncoder. data_transformer : A instance of transformer to process the data, See example as ImageDataTransformer. verbose : A boolean of whether the search process will be printed to stdout. path : A string. The path to a directory, where the intermediate results are saved.","title":"Attributes"},{"location":"temp/predefined_model/#_init_generator","text":"Initialize the generator to generate the model architecture.","title":"_init_generator"},{"location":"temp/predefined_model/#args","text":"n_output_node : A integer value represent the number of output node in the final layer. input_shape : A tuple to express the shape of every train entry.","title":"Args"},{"location":"temp/predefined_model/#fit","text":"Trains the model on the dataset given.","title":"fit"},{"location":"temp/predefined_model/#args_1","text":"x_train : A numpy.ndarray instance containing the training data, or the training data combined with the validation data. y_train : A numpy.ndarray instance containing the label of the training data, or the label of the training data combined with the validation label. time_limit : A dictionary containing the parameters of the ModelTrainer constructor.","title":"Args"},{"location":"temp/preprocessor/","text":"OneHotEncoder A class that can format data. This class provides ways to transform data's classification label into vector. Attributes data : The input data n_classes : The number of classes in the classification problem. labels : The number of labels. label_to_vec : Mapping from label to vector. int_to_label : Mapping from int to label. init Initialize a OneHotEncoder fit Create mapping from label to vector, and vector to label. transform Get vector for every element in the data array. inverse_transform Get label for every element in data. DataTransformer A superclass for all the DataTransformer. transform_train Transform the training data and get the DataLoader class. Args data : x. targets : y. batch_size : the batch size. Returns dataloader : A torch.DataLoader class to represent the transformed data. transform_test Transform the training data and get the DataLoader class. Args data : x. targets : y. batch_size : the batch size. Returns dataloader : A torch.DataLoader class to represent the transformed data.","title":"preprocessor"},{"location":"temp/preprocessor/#onehotencoder","text":"A class that can format data. This class provides ways to transform data's classification label into vector.","title":"OneHotEncoder"},{"location":"temp/preprocessor/#attributes","text":"data : The input data n_classes : The number of classes in the classification problem. labels : The number of labels. label_to_vec : Mapping from label to vector. int_to_label : Mapping from int to label.","title":"Attributes"},{"location":"temp/preprocessor/#init","text":"Initialize a OneHotEncoder","title":"init"},{"location":"temp/preprocessor/#fit","text":"Create mapping from label to vector, and vector to label.","title":"fit"},{"location":"temp/preprocessor/#transform","text":"Get vector for every element in the data array.","title":"transform"},{"location":"temp/preprocessor/#inverse_transform","text":"Get label for every element in data.","title":"inverse_transform"},{"location":"temp/preprocessor/#datatransformer","text":"A superclass for all the DataTransformer.","title":"DataTransformer"},{"location":"temp/preprocessor/#transform_train","text":"Transform the training data and get the DataLoader class.","title":"transform_train"},{"location":"temp/preprocessor/#args","text":"data : x. targets : y. batch_size : the batch size.","title":"Args"},{"location":"temp/preprocessor/#returns","text":"dataloader : A torch.DataLoader class to represent the transformed data.","title":"Returns"},{"location":"temp/preprocessor/#transform_test","text":"Transform the training data and get the DataLoader class.","title":"transform_test"},{"location":"temp/preprocessor/#args_1","text":"data : x. targets : y. batch_size : the batch size.","title":"Args"},{"location":"temp/preprocessor/#returns_1","text":"dataloader : A torch.DataLoader class to represent the transformed data.","title":"Returns"},{"location":"temp/pretrained/","text":"","title":"Pretrained"},{"location":"temp/search/","text":"train Train the neural architecture. Searcher The base class to search for neural architectures. This class generate new architectures, call the trainer to train it, and update the optimizer. Attributes n_classes : Number of classes in the target classification task. input_shape : Arbitrary, although all dimensions in the input shaped must be fixed. Use the keyword argument input_shape (tuple of integers, does not include the batch axis) when using this layer as the first layer in a model. verbose : Verbosity mode. history : A list that stores the performance of model. Each element in it is a dictionary of 'model_id', 'loss', and 'metric_value'. neighbour_history : A list that stores the performance of neighbor of the best model. Each element in it is a dictionary of 'model_id', 'loss', and 'metric_value'. path : A string. The path to the directory for saving the searcher. metric : An instance of the Metric subclasses. loss : A function taking two parameters, the predictions and the ground truth. generators : A list of generators used to initialize the search. model_count : An integer. the total number of neural networks in the current searcher. descriptors : A dictionary of all the neural network architectures searched. trainer_args : A dictionary. The params for the constructor of ModelTrainer. default_model_len : An integer. Number of convolutional layers in the initial architecture. default_model_width : An integer. The number of filters in each layer in the initial architecture. training_queue : A list of the generated architectures to be trained. x_queue : A list of trained architectures not updated to the gpr. y_queue : A list of trained architecture performances not updated to the gpr. init Initialize the Searcher. Args n_output_node : An integer, the number of classes. input_shape : A tuple. e.g. (28, 28, 1). path : A string. The path to the directory to save the searcher. metric : An instance of the Metric subclasses. loss : A function taking two parameters, the predictions and the ground truth. generators : A list of generators used to initialize the search. verbose : A boolean. Whether to output the intermediate information to stdout. trainer_args : A dictionary. The params for the constructor of ModelTrainer. default_model_len : An integer. Number of convolutional layers in the initial architecture. default_model_width : An integer. The number of filters in each layer in the initial architecture. init_search Call the generators to generate the initial architectures for the search. search Run the search loop of training, generating and updating once. The function will run the training and generate in parallel. Then it will update the controller. The training is just pop out a graph from the training_queue and train it. The generate will call the self.generate function. The update will call the self.update function. Args train_data : An instance of DataLoader. test_data : An instance of Dataloader. timeout : An integer, time limit in seconds. generate Generate the next neural architecture. Args multiprocessing_queue : the Queue for multiprocessing return value. Returns list of 2-element tuples : generated_graph and other_info, generated_graph : An instance of Graph. other_info : Anything to be saved in the training queue together update Update the controller with evaluation result of a neural architecture. Args other_info : Anything. In the case of default bayesian searcher, it is the father ID in the search tree. model_id : An integer. graph : An instance of Graph. The trained neural architecture. metric_value : The final evaluated metric value. add_model Append the information of evaluated architecture to history. BayesianSearcher Class to search for neural architectures using Bayesian search strategy. Attribute: optimizer: An instance of BayesianOptimizer. t_min: A float. The minimum temperature during simulated annealing. generate Generate the next neural architecture. Args multiprocessing_queue : the Queue for multiprocessing return value. Returns list of 2-element tuples : generated_graph and other_info, generated_graph : An instance of Graph. other_info : Anything to be saved in the training queue together with the architecture. update Update the controller with evaluation result of a neural architecture. Args other_info : Anything. In our case it is the father ID in the search tree. model_id : An integer. graph : An instance of Graph. The trained neural architecture. metric_value : The final evaluated metric value.","title":"search"},{"location":"temp/search/#train","text":"Train the neural architecture.","title":"train"},{"location":"temp/search/#searcher","text":"The base class to search for neural architectures. This class generate new architectures, call the trainer to train it, and update the optimizer.","title":"Searcher"},{"location":"temp/search/#attributes","text":"n_classes : Number of classes in the target classification task. input_shape : Arbitrary, although all dimensions in the input shaped must be fixed. Use the keyword argument input_shape (tuple of integers, does not include the batch axis) when using this layer as the first layer in a model. verbose : Verbosity mode. history : A list that stores the performance of model. Each element in it is a dictionary of 'model_id', 'loss', and 'metric_value'. neighbour_history : A list that stores the performance of neighbor of the best model. Each element in it is a dictionary of 'model_id', 'loss', and 'metric_value'. path : A string. The path to the directory for saving the searcher. metric : An instance of the Metric subclasses. loss : A function taking two parameters, the predictions and the ground truth. generators : A list of generators used to initialize the search. model_count : An integer. the total number of neural networks in the current searcher. descriptors : A dictionary of all the neural network architectures searched. trainer_args : A dictionary. The params for the constructor of ModelTrainer. default_model_len : An integer. Number of convolutional layers in the initial architecture. default_model_width : An integer. The number of filters in each layer in the initial architecture. training_queue : A list of the generated architectures to be trained. x_queue : A list of trained architectures not updated to the gpr. y_queue : A list of trained architecture performances not updated to the gpr.","title":"Attributes"},{"location":"temp/search/#init","text":"Initialize the Searcher.","title":"init"},{"location":"temp/search/#args","text":"n_output_node : An integer, the number of classes. input_shape : A tuple. e.g. (28, 28, 1). path : A string. The path to the directory to save the searcher. metric : An instance of the Metric subclasses. loss : A function taking two parameters, the predictions and the ground truth. generators : A list of generators used to initialize the search. verbose : A boolean. Whether to output the intermediate information to stdout. trainer_args : A dictionary. The params for the constructor of ModelTrainer. default_model_len : An integer. Number of convolutional layers in the initial architecture. default_model_width : An integer. The number of filters in each layer in the initial architecture.","title":"Args"},{"location":"temp/search/#init_search","text":"Call the generators to generate the initial architectures for the search.","title":"init_search"},{"location":"temp/search/#search","text":"Run the search loop of training, generating and updating once. The function will run the training and generate in parallel. Then it will update the controller. The training is just pop out a graph from the training_queue and train it. The generate will call the self.generate function. The update will call the self.update function.","title":"search"},{"location":"temp/search/#args_1","text":"train_data : An instance of DataLoader. test_data : An instance of Dataloader. timeout : An integer, time limit in seconds.","title":"Args"},{"location":"temp/search/#generate","text":"Generate the next neural architecture.","title":"generate"},{"location":"temp/search/#args_2","text":"multiprocessing_queue : the Queue for multiprocessing return value.","title":"Args"},{"location":"temp/search/#returns","text":"list of 2-element tuples : generated_graph and other_info, generated_graph : An instance of Graph. other_info : Anything to be saved in the training queue together","title":"Returns"},{"location":"temp/search/#update","text":"Update the controller with evaluation result of a neural architecture.","title":"update"},{"location":"temp/search/#args_3","text":"other_info : Anything. In the case of default bayesian searcher, it is the father ID in the search tree. model_id : An integer. graph : An instance of Graph. The trained neural architecture. metric_value : The final evaluated metric value.","title":"Args"},{"location":"temp/search/#add_model","text":"Append the information of evaluated architecture to history.","title":"add_model"},{"location":"temp/search/#bayesiansearcher","text":"Class to search for neural architectures using Bayesian search strategy. Attribute: optimizer: An instance of BayesianOptimizer. t_min: A float. The minimum temperature during simulated annealing.","title":"BayesianSearcher"},{"location":"temp/search/#generate_1","text":"Generate the next neural architecture.","title":"generate"},{"location":"temp/search/#args_4","text":"multiprocessing_queue : the Queue for multiprocessing return value.","title":"Args"},{"location":"temp/search/#returns_1","text":"list of 2-element tuples : generated_graph and other_info, generated_graph : An instance of Graph. other_info : Anything to be saved in the training queue together with the architecture.","title":"Returns"},{"location":"temp/search/#update_1","text":"Update the controller with evaluation result of a neural architecture.","title":"update"},{"location":"temp/search/#args_5","text":"other_info : Anything. In our case it is the father ID in the search tree. model_id : An integer. graph : An instance of Graph. The trained neural architecture. metric_value : The final evaluated metric value.","title":"Args"},{"location":"temp/supervised/","text":"Supervised The base class for all supervised tasks. Attributes verbose : A boolean value indicating the verbosity mode. init Initialize the instance of the class. Args verbose : A boolean of whether the search process will be printed to stdout. (optional, default = False) fit Find the best neural architecture for classifying the training data and train it. Based on the given dataset, the function will find the best neural architecture for it. The dataset must be in numpy.ndarray format. So the training data should be passed through x_train , y_train . Args x_train : A numpy.ndarray instance containing the training data or the training data combined with the validation data. y_train : A numpy.ndarray instance containing the labels of the training data. or the label of the training data combined with the validation label. time_limit : The time limit for the search in seconds. cts : predict Return the results for the testing data predicted by the best neural architecture. Dependent on the results of the fit() function. Args x_test : An instance of numpy.ndarray containing the testing data. Returns evaluate Return the accuracy score between predict value and y_test . Args x_test : An instance of numpy.ndarray containing the testing data y_test : An instance of numpy.ndarray containing the labels of the testing data Returns SearchSupervised The base class for all supervised tasks using neural architecture search. Inherits from Supervised class. Attributes verbose : A boolean value indicating the verbosity mode. final_fit Final training after finding the best neural architecture. Args x_train : A numpy.ndarray of training data. y_train : A numpy.ndarray of training targets. x_test : A numpy.ndarray of testing data. y_test : A numpy.ndarray of testing targets. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. (optional, default = None) retrain : A boolean of whether reinitialize the weights of the model. (optional, default = False) DeepTaskSupervised Inherits from SearchSupervised class. Attributes verbose : A boolean value indicating the verbosity mode. (optional, default = False) path : A string indicating the path to a directory where the intermediate results are saved. (optional, default = None) resume : A boolean. If True, the classifier will continue to previous work saved in path. Otherwise, the classifier will start a new search. (optional, default = False) searcher_args : A dictionary containing the parameters for the searcher's init function. (optional, default = None) search_type : A constant denoting the type of hyperparameter search algorithm that must be used. (optional, default = BayesianSearcher) init Initialize the instance of a DeepTaskSupervised class. The classifier will be loaded from the files in 'path' if parameter 'resume' is True. Otherwise it would create a new one. Args verbose : A boolean of whether the search process will be printed to stdout. path : A string. The path to a directory, where the intermediate results are saved. resume : A boolean. If True, the classifier will continue to previous work saved in path. Otherwise, the classifier will start a new search. searcher_args : A dictionary containing the parameters for the searcher's init function. search_type : A constant denoting the type of hyperparameter search algorithm that must be used. fit Find the best neural architecture for classifying the training data and train it. Based on the given dataset, the function will find the best neural architecture for it. The dataset must be in numpy.ndarray format. The training and validation data should be passed through x , y . This method will automatically split the training and validation data into training and validation sets. Args x : A numpy.ndarray instance containing the training data or the training data combined with the validation data. y : A numpy.ndarray instance containing the labels of the training data. or the label of the training data combined with the validation label. time_limit : The time limit for the search in seconds. (optional, default = None, which turns into 24 hours in method) cts : final_fit Final training after found the best architecture. Args x_train : A numpy.ndarray of training data. y_train : A numpy.ndarray of training targets. x_test : A numpy.ndarray of testing data. y_test : A numpy.ndarray of testing targets. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean indicating whether or not to reinitialize the weights of the model. export_keras_model Exports the best Keras model to the given filename. Args model_file_name : A string of the filename to which the best model will be exported cts : predict Return predict results for the testing data. Args x_test : An instance of numpy.ndarray containing the testing data. Returns evaluate Return the accuracy score between predict value and y_test . Predict the labels for the testing data. Calculate the accuracy metric between the predicted and actual labels of the testing data. Args x_test : An instance of numpy.ndarray containing the testing data y_test : An instance of numpy.ndarray containing the labels of the testing data Returns SingleModelSupervised The base class for all supervised tasks that do not use neural architecture search. Inherits from Supervised class. Attributes verbose : A boolean of whether the search process will be printed to stdout. path : A string value indicating the path to the directory where the intermediate model results are stored graph : The graph form of the learned model. data_transformer : A transformer class to process the data. (See example ImageDataTransformer .) init Initialize the instance of the SingleModelSupervised class. Args verbose : A boolean of whether the search process will be printed to stdout. (optional, default = False) path : A string. The path to a directory, where the intermediate results are saved. (optional, default = None) predict Return the predicted labels for the testing data. Args x_test : An instance of numpy.ndarray containing the testing data. Returns evaluate Return the accuracy score between predict value and y_test . Predict the labels for the testing data. Calculate the accuracy metric between the predicted and actual labels of the testing data. Args x_test : An instance of numpy.ndarray containing the testing data y_test : An instance of numpy.ndarray containing the labels of the testing data Returns save Exports the Keras model to the given filename. Args model_path : A string of the path to which the model will be saved cts : PortableDeepSupervised The basis class for exported keras model Inheirits from SingleModelSupervised class and abc module. Attributes graph : The graph form of the learned model. y_encoder : The encoder of the label. (See example OneHotEncoder .) data_transformer : A transformer class to process the data. (See example ImageDataTransformer .) verbose : A boolean of whether the search process will be printed to stdout. path : A string value indicating the path to the directory where the intermediate model results are stored init Initialize the instance of the PortableDeepSupervised class. Args graph : The graph form of the learned model. y_encoder : The encoder of the label. See example as OneHotEncoder data_transformer : A transformer class to process the data. See example as ImageDataTransformer. verbose : A boolean of whether the search process will be printed to stdout. path : A string. The path to a directory, where the intermediate results are saved. fit Trains the model on the given dataset. Args x : A numpy.ndarray instance containing the training data or the training data combined with the validation data. y : A numpy.ndarray instance containing the label of the training data. or the label of the training data combined with the validation label. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model.","title":"supervised"},{"location":"temp/supervised/#supervised","text":"The base class for all supervised tasks.","title":"Supervised"},{"location":"temp/supervised/#attributes","text":"verbose : A boolean value indicating the verbosity mode.","title":"Attributes"},{"location":"temp/supervised/#init","text":"Initialize the instance of the class.","title":"init"},{"location":"temp/supervised/#args","text":"verbose : A boolean of whether the search process will be printed to stdout. (optional, default = False)","title":"Args"},{"location":"temp/supervised/#fit","text":"Find the best neural architecture for classifying the training data and train it. Based on the given dataset, the function will find the best neural architecture for it. The dataset must be in numpy.ndarray format. So the training data should be passed through x_train , y_train .","title":"fit"},{"location":"temp/supervised/#args_1","text":"x_train : A numpy.ndarray instance containing the training data or the training data combined with the validation data. y_train : A numpy.ndarray instance containing the labels of the training data. or the label of the training data combined with the validation label. time_limit : The time limit for the search in seconds. cts :","title":"Args"},{"location":"temp/supervised/#predict","text":"Return the results for the testing data predicted by the best neural architecture. Dependent on the results of the fit() function.","title":"predict"},{"location":"temp/supervised/#args_2","text":"x_test : An instance of numpy.ndarray containing the testing data.","title":"Args"},{"location":"temp/supervised/#returns","text":"","title":"Returns"},{"location":"temp/supervised/#evaluate","text":"Return the accuracy score between predict value and y_test .","title":"evaluate"},{"location":"temp/supervised/#args_3","text":"x_test : An instance of numpy.ndarray containing the testing data y_test : An instance of numpy.ndarray containing the labels of the testing data","title":"Args"},{"location":"temp/supervised/#returns_1","text":"","title":"Returns"},{"location":"temp/supervised/#searchsupervised","text":"The base class for all supervised tasks using neural architecture search. Inherits from Supervised class.","title":"SearchSupervised"},{"location":"temp/supervised/#attributes_1","text":"verbose : A boolean value indicating the verbosity mode.","title":"Attributes"},{"location":"temp/supervised/#final_fit","text":"Final training after finding the best neural architecture.","title":"final_fit"},{"location":"temp/supervised/#args_4","text":"x_train : A numpy.ndarray of training data. y_train : A numpy.ndarray of training targets. x_test : A numpy.ndarray of testing data. y_test : A numpy.ndarray of testing targets. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. (optional, default = None) retrain : A boolean of whether reinitialize the weights of the model. (optional, default = False)","title":"Args"},{"location":"temp/supervised/#deeptasksupervised","text":"Inherits from SearchSupervised class.","title":"DeepTaskSupervised"},{"location":"temp/supervised/#attributes_2","text":"verbose : A boolean value indicating the verbosity mode. (optional, default = False) path : A string indicating the path to a directory where the intermediate results are saved. (optional, default = None) resume : A boolean. If True, the classifier will continue to previous work saved in path. Otherwise, the classifier will start a new search. (optional, default = False) searcher_args : A dictionary containing the parameters for the searcher's init function. (optional, default = None) search_type : A constant denoting the type of hyperparameter search algorithm that must be used. (optional, default = BayesianSearcher)","title":"Attributes"},{"location":"temp/supervised/#init_1","text":"Initialize the instance of a DeepTaskSupervised class. The classifier will be loaded from the files in 'path' if parameter 'resume' is True. Otherwise it would create a new one.","title":"init"},{"location":"temp/supervised/#args_5","text":"verbose : A boolean of whether the search process will be printed to stdout. path : A string. The path to a directory, where the intermediate results are saved. resume : A boolean. If True, the classifier will continue to previous work saved in path. Otherwise, the classifier will start a new search. searcher_args : A dictionary containing the parameters for the searcher's init function. search_type : A constant denoting the type of hyperparameter search algorithm that must be used.","title":"Args"},{"location":"temp/supervised/#fit_1","text":"Find the best neural architecture for classifying the training data and train it. Based on the given dataset, the function will find the best neural architecture for it. The dataset must be in numpy.ndarray format. The training and validation data should be passed through x , y . This method will automatically split the training and validation data into training and validation sets.","title":"fit"},{"location":"temp/supervised/#args_6","text":"x : A numpy.ndarray instance containing the training data or the training data combined with the validation data. y : A numpy.ndarray instance containing the labels of the training data. or the label of the training data combined with the validation label. time_limit : The time limit for the search in seconds. (optional, default = None, which turns into 24 hours in method) cts :","title":"Args"},{"location":"temp/supervised/#final_fit_1","text":"Final training after found the best architecture.","title":"final_fit"},{"location":"temp/supervised/#args_7","text":"x_train : A numpy.ndarray of training data. y_train : A numpy.ndarray of training targets. x_test : A numpy.ndarray of testing data. y_test : A numpy.ndarray of testing targets. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean indicating whether or not to reinitialize the weights of the model.","title":"Args"},{"location":"temp/supervised/#export_keras_model","text":"Exports the best Keras model to the given filename.","title":"export_keras_model"},{"location":"temp/supervised/#args_8","text":"model_file_name : A string of the filename to which the best model will be exported cts :","title":"Args"},{"location":"temp/supervised/#predict_1","text":"Return predict results for the testing data.","title":"predict"},{"location":"temp/supervised/#args_9","text":"x_test : An instance of numpy.ndarray containing the testing data.","title":"Args"},{"location":"temp/supervised/#returns_2","text":"","title":"Returns"},{"location":"temp/supervised/#evaluate_1","text":"Return the accuracy score between predict value and y_test . Predict the labels for the testing data. Calculate the accuracy metric between the predicted and actual labels of the testing data.","title":"evaluate"},{"location":"temp/supervised/#args_10","text":"x_test : An instance of numpy.ndarray containing the testing data y_test : An instance of numpy.ndarray containing the labels of the testing data","title":"Args"},{"location":"temp/supervised/#returns_3","text":"","title":"Returns"},{"location":"temp/supervised/#singlemodelsupervised","text":"The base class for all supervised tasks that do not use neural architecture search. Inherits from Supervised class.","title":"SingleModelSupervised"},{"location":"temp/supervised/#attributes_3","text":"verbose : A boolean of whether the search process will be printed to stdout. path : A string value indicating the path to the directory where the intermediate model results are stored graph : The graph form of the learned model. data_transformer : A transformer class to process the data. (See example ImageDataTransformer .)","title":"Attributes"},{"location":"temp/supervised/#init_2","text":"Initialize the instance of the SingleModelSupervised class.","title":"init"},{"location":"temp/supervised/#args_11","text":"verbose : A boolean of whether the search process will be printed to stdout. (optional, default = False) path : A string. The path to a directory, where the intermediate results are saved. (optional, default = None)","title":"Args"},{"location":"temp/supervised/#predict_2","text":"Return the predicted labels for the testing data.","title":"predict"},{"location":"temp/supervised/#args_12","text":"x_test : An instance of numpy.ndarray containing the testing data.","title":"Args"},{"location":"temp/supervised/#returns_4","text":"","title":"Returns"},{"location":"temp/supervised/#evaluate_2","text":"Return the accuracy score between predict value and y_test . Predict the labels for the testing data. Calculate the accuracy metric between the predicted and actual labels of the testing data.","title":"evaluate"},{"location":"temp/supervised/#args_13","text":"x_test : An instance of numpy.ndarray containing the testing data y_test : An instance of numpy.ndarray containing the labels of the testing data","title":"Args"},{"location":"temp/supervised/#returns_5","text":"","title":"Returns"},{"location":"temp/supervised/#save","text":"Exports the Keras model to the given filename.","title":"save"},{"location":"temp/supervised/#args_14","text":"model_path : A string of the path to which the model will be saved cts :","title":"Args"},{"location":"temp/supervised/#portabledeepsupervised","text":"The basis class for exported keras model Inheirits from SingleModelSupervised class and abc module.","title":"PortableDeepSupervised"},{"location":"temp/supervised/#attributes_4","text":"graph : The graph form of the learned model. y_encoder : The encoder of the label. (See example OneHotEncoder .) data_transformer : A transformer class to process the data. (See example ImageDataTransformer .) verbose : A boolean of whether the search process will be printed to stdout. path : A string value indicating the path to the directory where the intermediate model results are stored","title":"Attributes"},{"location":"temp/supervised/#init_3","text":"Initialize the instance of the PortableDeepSupervised class.","title":"init"},{"location":"temp/supervised/#args_15","text":"graph : The graph form of the learned model. y_encoder : The encoder of the label. See example as OneHotEncoder data_transformer : A transformer class to process the data. See example as ImageDataTransformer. verbose : A boolean of whether the search process will be printed to stdout. path : A string. The path to a directory, where the intermediate results are saved.","title":"Args"},{"location":"temp/supervised/#fit_2","text":"Trains the model on the given dataset.","title":"fit"},{"location":"temp/supervised/#args_16","text":"x : A numpy.ndarray instance containing the training data or the training data combined with the validation data. y : A numpy.ndarray instance containing the label of the training data. or the label of the training data combined with the validation label. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model.","title":"Args"},{"location":"temp/text_supervised/","text":"TextSupervised fit Train the text classifier/regressor on the training data. Args x : ndarray containing the train data inputs. y : ndarray containing the train data outputs/labels. time_limit : Maximum time allowed for searching. It does not apply for this classifier. predict Predict the labels/outputs for the provided input data. Args x_test : ndarray containing the test data inputs. Returns preprocess Preprocess text data. Tokenize the input text and convert into features. Args x : Text input. Returns all_input_ids : ndarray containing the ids for each token. all_input_masks : ndarray containing 1's or 0's based on if the tokens are real or padded. all_segment_ids : ndarray containing all 0's since it is a classification task. TextRegressor init Initialize the TextClassifier. Args verbose : Mode of verbosity. TextClassifier A TextClassifier class based on Google AI's BERT model. Attributes device : Specific hardware for using/running the model. E.g verbose : Mode of verbosity. bert_model : Type of BERT model to be used for the classification task. E.g tokenizer : Tokenizer used with BERT model. num_labels : Number of output labels for the classification task. output_model_file : File location to save the trained model. init Initialize the TextClassifier. Args verbose : Mode of verbosity.","title":"Text supervised"},{"location":"temp/text_supervised/#textsupervised","text":"","title":"TextSupervised"},{"location":"temp/text_supervised/#fit","text":"Train the text classifier/regressor on the training data.","title":"fit"},{"location":"temp/text_supervised/#args","text":"x : ndarray containing the train data inputs. y : ndarray containing the train data outputs/labels. time_limit : Maximum time allowed for searching. It does not apply for this classifier.","title":"Args"},{"location":"temp/text_supervised/#predict","text":"Predict the labels/outputs for the provided input data.","title":"predict"},{"location":"temp/text_supervised/#args_1","text":"x_test : ndarray containing the test data inputs.","title":"Args"},{"location":"temp/text_supervised/#returns","text":"","title":"Returns"},{"location":"temp/text_supervised/#preprocess","text":"Preprocess text data. Tokenize the input text and convert into features.","title":"preprocess"},{"location":"temp/text_supervised/#args_2","text":"x : Text input.","title":"Args"},{"location":"temp/text_supervised/#returns_1","text":"all_input_ids : ndarray containing the ids for each token. all_input_masks : ndarray containing 1's or 0's based on if the tokens are real or padded. all_segment_ids : ndarray containing all 0's since it is a classification task.","title":"Returns"},{"location":"temp/text_supervised/#textregressor","text":"","title":"TextRegressor"},{"location":"temp/text_supervised/#init","text":"Initialize the TextClassifier.","title":"init"},{"location":"temp/text_supervised/#args_3","text":"verbose : Mode of verbosity.","title":"Args"},{"location":"temp/text_supervised/#textclassifier","text":"A TextClassifier class based on Google AI's BERT model.","title":"TextClassifier"},{"location":"temp/text_supervised/#attributes","text":"device : Specific hardware for using/running the model. E.g verbose : Mode of verbosity. bert_model : Type of BERT model to be used for the classification task. E.g tokenizer : Tokenizer used with BERT model. num_labels : Number of output labels for the classification task. output_model_file : File location to save the trained model.","title":"Attributes"},{"location":"temp/text_supervised/#init_1","text":"Initialize the TextClassifier.","title":"init"},{"location":"temp/text_supervised/#args_4","text":"verbose : Mode of verbosity.","title":"Args"},{"location":"temp/tokenization/","text":"load_vocab Loads a vocabulary file into a dictionary. whitespace_tokenize Runs basic whitespace cleaning and splitting on a peice of text. _is_whitespace Checks whether chars is a whitespace character. _is_control Checks whether chars is a control character. _is_punctuation Checks whether chars is a punctuation character. BertTokenizer Runs end-to-end tokenization: punctuation splitting + wordpiece convert_tokens_to_ids Converts a sequence of tokens into ids using the vocab. from_pretrained Instantiate a PreTrainedBertModel from a pre-trained model file. Download and cache the pre-trained model file if needed. BasicTokenizer Runs basic tokenization (punctuation splitting, lower casing, etc.). init Constructs a BasicTokenizer. Args do_lower_case : Whether to lower case the input. tokenize Tokenizes a piece of text. _run_strip_accents Strips accents from a piece of text. _run_split_on_punc Splits punctuation on a piece of text. _tokenize_chinese_chars Adds whitespace around any CJK character. _is_chinese_char Checks whether CP is the codepoint of a CJK character. _clean_text Performs invalid character removal and whitespace cleanup on text. WordpieceTokenizer Runs WordPiece tokenization. tokenize Tokenizes a piece of text into its word pieces. This uses a greedy longest-match-first algorithm to perform tokenization using the given vocabulary. For example: input = \"unaffable\" output = [\"un\", \"##aff\", \"##able\"] Args text : A single token or whitespace separated tokens. This should have already been passed through `BasicTokenizer. Returns","title":"Tokenization"},{"location":"temp/tokenization/#load_vocab","text":"Loads a vocabulary file into a dictionary.","title":"load_vocab"},{"location":"temp/tokenization/#whitespace_tokenize","text":"Runs basic whitespace cleaning and splitting on a peice of text.","title":"whitespace_tokenize"},{"location":"temp/tokenization/#_is_whitespace","text":"Checks whether chars is a whitespace character.","title":"_is_whitespace"},{"location":"temp/tokenization/#_is_control","text":"Checks whether chars is a control character.","title":"_is_control"},{"location":"temp/tokenization/#_is_punctuation","text":"Checks whether chars is a punctuation character.","title":"_is_punctuation"},{"location":"temp/tokenization/#berttokenizer","text":"Runs end-to-end tokenization: punctuation splitting + wordpiece","title":"BertTokenizer"},{"location":"temp/tokenization/#convert_tokens_to_ids","text":"Converts a sequence of tokens into ids using the vocab.","title":"convert_tokens_to_ids"},{"location":"temp/tokenization/#from_pretrained","text":"Instantiate a PreTrainedBertModel from a pre-trained model file. Download and cache the pre-trained model file if needed.","title":"from_pretrained"},{"location":"temp/tokenization/#basictokenizer","text":"Runs basic tokenization (punctuation splitting, lower casing, etc.).","title":"BasicTokenizer"},{"location":"temp/tokenization/#init","text":"Constructs a BasicTokenizer.","title":"init"},{"location":"temp/tokenization/#args","text":"do_lower_case : Whether to lower case the input.","title":"Args"},{"location":"temp/tokenization/#tokenize","text":"Tokenizes a piece of text.","title":"tokenize"},{"location":"temp/tokenization/#_run_strip_accents","text":"Strips accents from a piece of text.","title":"_run_strip_accents"},{"location":"temp/tokenization/#_run_split_on_punc","text":"Splits punctuation on a piece of text.","title":"_run_split_on_punc"},{"location":"temp/tokenization/#_tokenize_chinese_chars","text":"Adds whitespace around any CJK character.","title":"_tokenize_chinese_chars"},{"location":"temp/tokenization/#_is_chinese_char","text":"Checks whether CP is the codepoint of a CJK character.","title":"_is_chinese_char"},{"location":"temp/tokenization/#_clean_text","text":"Performs invalid character removal and whitespace cleanup on text.","title":"_clean_text"},{"location":"temp/tokenization/#wordpiecetokenizer","text":"Runs WordPiece tokenization.","title":"WordpieceTokenizer"},{"location":"temp/tokenization/#tokenize_1","text":"Tokenizes a piece of text into its word pieces. This uses a greedy longest-match-first algorithm to perform tokenization using the given vocabulary. For example: input = \"unaffable\" output = [\"un\", \"##aff\", \"##able\"]","title":"tokenize"},{"location":"temp/tokenization/#args_1","text":"text : A single token or whitespace separated tokens. This should have already been passed through `BasicTokenizer.","title":"Args"},{"location":"temp/tokenization/#returns","text":"","title":"Returns"},{"location":"temp/unsupervised/","text":"Unsupervised The base class for all unsupervised task Attributes verbose : A boolean value indicating the verbosity mode. init Args: verbose: A boolean of whether the search process will be printed to stdout. fit Args: x_train: A numpy.ndarray instance containing the training data. generate Args: A numpy.ndarray or torch.tensor input fed into the model to generate the output","title":"Unsupervised"},{"location":"temp/unsupervised/#unsupervised","text":"The base class for all unsupervised task","title":"Unsupervised"},{"location":"temp/unsupervised/#attributes","text":"verbose : A boolean value indicating the verbosity mode.","title":"Attributes"},{"location":"temp/unsupervised/#init","text":"Args: verbose: A boolean of whether the search process will be printed to stdout.","title":"init"},{"location":"temp/unsupervised/#fit","text":"Args: x_train: A numpy.ndarray instance containing the training data.","title":"fit"},{"location":"temp/unsupervised/#generate","text":"Args: A numpy.ndarray or torch.tensor input fed into the model to generate the output","title":"generate"},{"location":"temp/utils/","text":"convert_examples_to_features Convert text examples to BERT specific input format. Tokenize the input text and convert into features. Args examples : Text data. tokenizer : Tokenizer to process the text into tokens. max_seq_length : The maximum length of the text sequence supported. Returns all_input_ids : ndarray containing the ids for each token. all_input_masks : ndarray containing 1's or 0's based on if the tokens are real or padded. all_segment_ids : ndarray containing all 0's since it is a classification task. InputFeatures A single set of features of data.","title":"utils"},{"location":"temp/utils/#convert_examples_to_features","text":"Convert text examples to BERT specific input format. Tokenize the input text and convert into features.","title":"convert_examples_to_features"},{"location":"temp/utils/#args","text":"examples : Text data. tokenizer : Tokenizer to process the text into tokens. max_seq_length : The maximum length of the text sequence supported.","title":"Args"},{"location":"temp/utils/#returns","text":"all_input_ids : ndarray containing the ids for each token. all_input_masks : ndarray containing 1's or 0's based on if the tokens are real or padded. all_segment_ids : ndarray containing all 0's since it is a classification task.","title":"Returns"},{"location":"temp/utils/#inputfeatures","text":"A single set of features of data.","title":"InputFeatures"}]}